{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "\n",
    "dataRep = '../data/'\n",
    "scriptRep = '../kuzushiji_recognition/'\n",
    "\n",
    "# some_file.py\n",
    "import sys\n",
    "# insert at 1, 0 is the script path (or '' in REPL)\n",
    "sys.path.insert(1, scriptRep)\n",
    "import progressBar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "683464 (32, 32, 1) 478424 580944\n"
     ]
    }
   ],
   "source": [
    "testFrac = 0.15\n",
    "valFrac = 0.15\n",
    "\n",
    "unicodeData = pd.read_csv(dataRep+'unicode_translation.csv')\n",
    "\n",
    "raw = np.load('../data/dataset/caracterClassificationFull.npz')\n",
    "image = np.expand_dims(raw['image'], 3).copy()\n",
    "charOutput = raw['characterClass'].copy()\n",
    "del raw\n",
    "\n",
    "index = np.arange(image.shape[0])\n",
    "np.random.shuffle(index)\n",
    "image = image[index]/255.0\n",
    "charOutput = charOutput[index]\n",
    "del index\n",
    "\n",
    "nFrac = int(image.shape[0]*(1.-testFrac))\n",
    "nVal = int(image.shape[0]*(1.-testFrac-valFrac))\n",
    "print(image.shape[0], image.shape[1:], nVal, nFrac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainAndEvaluateModel(model, filenameModel, batchSize):\n",
    "    \n",
    "    checkpoint = keras.callbacks.ModelCheckpoint(filepath=filenameModel,\n",
    "                                                 monitor='val_loss',\n",
    "                                                 verbose=0,\n",
    "                                                 save_best_only=True,\n",
    "                                                 mode='auto', period=1)\n",
    "    history = keras.callbacks.History()\n",
    "    reduceLR = keras.callbacks.ReduceLROnPlateau(monitor='val_loss',\n",
    "                                                 factor=0.1, patience=2,\n",
    "                                                 verbose=0,\n",
    "                                                 mode='auto')\n",
    "    earlyStop = keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                              min_delta=1e-7, patience=5,\n",
    "                                              verbose=0, mode='auto')\n",
    "    callbacks = [checkpoint, history, reduceLR, earlyStop]\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(image[:nVal], charOutput[:nVal], epochs=50, batch_size=batchSize,\n",
    "              validation_data=(image[nVal:nFrac], charOutput[nVal:nFrac]), shuffle=True, callbacks=callbacks)\n",
    "    \n",
    "    model = keras.models.load_model(filenameModel)\n",
    "    test_loss, test_acc = model.evaluate(image[nVal:nFrac], charOutput[nVal:nFrac])\n",
    "    \n",
    "    return test_loss\n",
    "\n",
    "\n",
    "def optimizeHyperParameter(funcCreateModel, filenameModel, dropoutLimit=(0,20), batchSizeLimit=(0,10), convolutionLayerLimit=(2,10), denseLayerLimit=(2,10), maxIter=30):\n",
    "    \n",
    "    i=0\n",
    "    stop=False\n",
    "    curentParam = [6, 5, 4, 8] # (dropout, batchsize, convolution, dense)\n",
    "    testedParam = np.zeros((dropoutLimit[1]+1, batchSizeLimit[1]+1, convolutionLayerLimit[1]+1, denseLayerLimit[1]+1), dtype=np.bool)\n",
    "    \n",
    "    stdLoss = trainAndEvaluateModel(funcCreateModel(curentParam[0]/20., 2**(curentParam[2]), 2**(curentParam[3])), filenameModel, 2**(curentParam[1]))\n",
    "    testedParam[curentParam[0], curentParam[1], curentParam[2], curentParam[3]] = True\n",
    "    \n",
    "    while (i<maxIter) and not stop:\n",
    "        i+=1\n",
    "        stop=True\n",
    "        \n",
    "        if (curentParam[0]-1) >= dropoutLimit[0] and not testedParam[curentParam[0]-1, curentParam[1], curentParam[2], curentParam[3]]:\n",
    "            print(\"Test dropout down\")\n",
    "            testLoss = trainAndEvaluateModel(funcCreateModel(float(curentParam[0]-1)/20., 2**(curentParam[2]), 2**(curentParam[3])),\n",
    "                                             'temp.h5', 2**(curentParam[1]))\n",
    "            testedParam[curentParam[0]-1, curentParam[1], curentParam[2], curentParam[3]] = True\n",
    "            \n",
    "            if testLoss < stdLoss:\n",
    "                stop=False\n",
    "                stdLoss = testLoss\n",
    "                curentParam[0] -= 1\n",
    "                os.system(\"cp temp.h5 \"+filenameModel)\n",
    "                print(\"New param set\", curentParam)\n",
    "            \n",
    "        if (curentParam[0]+1) <= dropoutLimit[1] and not testedParam[curentParam[0]+1, curentParam[1], curentParam[2], curentParam[3]]:\n",
    "            print(\"Test dropout up\")\n",
    "            testLoss = trainAndEvaluateModel(funcCreateModel(float(curentParam[0]+1)/20., 2**(curentParam[2]), 2**(curentParam[3])),\n",
    "                                             'temp.h5', 2**(curentParam[1]))\n",
    "            testedParam[curentParam[0]+1, curentParam[1], curentParam[2], curentParam[3]] = True\n",
    "            \n",
    "            if testLoss < stdLoss:\n",
    "                stop=False\n",
    "                stdLoss = testLoss\n",
    "                curentParam[0] += 1\n",
    "                os.system(\"cp temp.h5 \"+filenameModel)\n",
    "                print(\"New param set\", curentParam)\n",
    "                \n",
    "                \n",
    "        if (curentParam[1]-1) >= batchSizeLimit[0] and not testedParam[curentParam[0], curentParam[1]-1, curentParam[2], curentParam[3]]:\n",
    "            print(\"Test batchsize down\")\n",
    "            testLoss = trainAndEvaluateModel(funcCreateModel(curentParam[0]/20., 2**(curentParam[2]), 2**(curentParam[3])),\n",
    "                                             'temp.h5', 2**(curentParam[1]-1))\n",
    "            testedParam[curentParam[0], curentParam[1]-1, curentParam[2], curentParam[3]] = True\n",
    "            \n",
    "            if testLoss < stdLoss:\n",
    "                stop=False\n",
    "                stdLoss = testLoss\n",
    "                curentParam[1] -= 1\n",
    "                os.system(\"cp temp.h5 \"+filenameModel)\n",
    "                print(\"New param set\", curentParam)\n",
    "            \n",
    "        if (curentParam[1]+1) <= batchSizeLimit[1] and not testedParam[curentParam[0], curentParam[1]+1, curentParam[2], curentParam[3]]:\n",
    "            print(\"Test batchsize up\")\n",
    "            testLoss = trainAndEvaluateModel(funcCreateModel(curentParam[0]/20., 2**(curentParam[2]), 2**(curentParam[3])),\n",
    "                                             'temp.h5', 2**(curentParam[1]+1))\n",
    "            testedParam[curentParam[0], curentParam[1]+1, curentParam[2], curentParam[3]] = True\n",
    "            \n",
    "            if testLoss < stdLoss:\n",
    "                stop=False\n",
    "                stdLoss = testLoss\n",
    "                curentParam[1] += 1\n",
    "                os.system(\"cp temp.h5 \"+filenameModel)\n",
    "                print(\"New param set\", curentParam)\n",
    "                \n",
    "        if (curentParam[2]-1) >= convolutionLayerLimit[0] and not testedParam[curentParam[0], curentParam[1], curentParam[2]-1, curentParam[3]]:\n",
    "            print(\"Test convolution down\")\n",
    "            testLoss = trainAndEvaluateModel(funcCreateModel(curentParam[0]/20., 2**(curentParam[2]-1), 2**(curentParam[3])),\n",
    "                                             'temp.h5', 2**(curentParam[1]))\n",
    "            testedParam[curentParam[0], curentParam[1], curentParam[2]-1, curentParam[3]] = True\n",
    "            \n",
    "            if testLoss < stdLoss:\n",
    "                stop=False\n",
    "                stdLoss = testLoss\n",
    "                curentParam[2] -= 1\n",
    "                os.system(\"cp temp.h5 \"+filenameModel)\n",
    "                print(\"New param set\", curentParam)\n",
    "            \n",
    "        if (curentParam[2]+1) <= convolutionLayerLimit[1] and not testedParam[curentParam[0]-1, curentParam[1], curentParam[2]+1, curentParam[3]]:\n",
    "            print(\"Test convolution up\")\n",
    "            testLoss = trainAndEvaluateModel(funcCreateModel(curentParam[0]/20., 2**(curentParam[2]+1), 2**(curentParam[3])),\n",
    "                                             'temp.h5', 2**(curentParam[1]))\n",
    "            testedParam[curentParam[0]-1, curentParam[1], curentParam[2]+1, curentParam[3]] = True\n",
    "            \n",
    "            if testLoss < stdLoss:\n",
    "                stop=False\n",
    "                stdLoss = testLoss\n",
    "                curentParam[2] += 1\n",
    "                os.system(\"cp temp.h5 \"+filenameModel)\n",
    "                print(\"New param set\", curentParam)\n",
    "                \n",
    "        if (curentParam[3]-1) >= denseLayerLimit[0] and not testedParam[curentParam[0]-1, curentParam[1], curentParam[2], curentParam[3]-1]:\n",
    "            print(\"Test dense down\")\n",
    "            testLoss = trainAndEvaluateModel(funcCreateModel(curentParam[0]/20., 2**(curentParam[2]), 2**(curentParam[3]-1)),\n",
    "                                             'temp.h5', 2**(curentParam[1]))\n",
    "            testedParam[curentParam[0]-1, curentParam[1], curentParam[2], curentParam[3]-1] = True\n",
    "            \n",
    "            if testLoss < stdLoss:\n",
    "                stop=False\n",
    "                stdLoss = testLoss\n",
    "                curentParam[3] -= 1\n",
    "                os.system(\"cp temp.h5 \"+filenameModel)\n",
    "                print(\"New param set\", curentParam)\n",
    "            \n",
    "        if (curentParam[3]+1) <= denseLayerLimit[1] and not testedParam[curentParam[0]-1, curentParam[1], curentParam[2], curentParam[3]+1]:\n",
    "            print(\"Test dense up\")\n",
    "            testLoss = trainAndEvaluateModel(funcCreateModel(curentParam[0]/20., 2**(curentParam[2]), 2**(curentParam[3]+1)),\n",
    "                                             'temp.h5', 2**(curentParam[1]))\n",
    "            testedParam[curentParam[0]-1, curentParam[1], curentParam[2], curentParam[3]+1] = True\n",
    "            \n",
    "            if testLoss < stdLoss:\n",
    "                stop=False\n",
    "                stdLoss = testLoss\n",
    "                curentParam[3] += 1\n",
    "                os.system(\"cp temp.h5 \"+filenameModel)\n",
    "                print(\"New param set\", curentParam)\n",
    "                \n",
    "    print('Dropout :', curentParam[0])\n",
    "    print('Batch Size :', 2**curentParam[1])\n",
    "    print('Convolutional layer :', 2**curentParam[2])\n",
    "    print('Dense Layer :', 2**curentParam[3])\n",
    "    os.system(\"rm temp.h5\")\n",
    "    \n",
    "    print(\"Nb iteration\", i, \"/\", maxIter)\n",
    "    print(\"Nb case tested\", np.sum(testedParam), \"/\", np.sum(np.ones(testedParam.shape, dtype=np.bool)))\n",
    "        \n",
    "def createModel1(dropoutRate, convLayer, denseLayer):\n",
    "    \n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Conv2D(convLayer, (3, 3), activation='relu', input_shape=image.shape[1:]))\n",
    "    model.add(keras.layers.SpatialDropout2D(dropoutRate))\n",
    "    model.add(keras.layers.Conv2D(convLayer, (3, 3), activation='relu'))\n",
    "    model.add(keras.layers.SpatialDropout2D(dropoutRate))\n",
    "    model.add(keras.layers.MaxPooling2D((2, 2)))\n",
    "    model.add(keras.layers.Conv2D(convLayer*2, (3, 3), activation='relu'))\n",
    "    model.add(keras.layers.SpatialDropout2D(dropoutRate))\n",
    "    model.add(keras.layers.Conv2D(convLayer*2, (3, 3), activation='relu'))\n",
    "    model.add(keras.layers.SpatialDropout2D(dropoutRate))\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(denseLayer, activation='relu'))\n",
    "    model.add(keras.layers.Dropout(dropoutRate))\n",
    "    model.add(keras.layers.Dense(len(unicodeData), activation='softmax'))\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0904 14:12:56.266648 139978887604032 deprecation.py:506] From /home/mathieu/miniconda3/envs/mlearning/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0904 14:12:56.527713 139978887604032 callbacks.py:875] `period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 478424 samples, validate on 102520 samples\n",
      "Epoch 1/50\n",
      "  5632/478424 [..............................] - ETA: 16:45 - loss: 6.1924 - acc: 0.0332"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-ee2100078689>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moptimizeHyperParameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcreateModel1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'../models/KMNIST1.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-37275905a3a0>\u001b[0m in \u001b[0;36moptimizeHyperParameter\u001b[0;34m(funcCreateModel, filenameModel, dropoutLimit, batchSizeLimit, convolutionLayerLimit, denseLayerLimit, maxIter)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mtestedParam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdropoutLimit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatchSizeLimit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvolutionLayerLimit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenseLayerLimit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mstdLoss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainAndEvaluateModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfuncCreateModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurentParam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m20.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurentParam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurentParam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilenameModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurentParam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0mtestedParam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcurentParam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurentParam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurentParam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurentParam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-37275905a3a0>\u001b[0m in \u001b[0;36mtrainAndEvaluateModel\u001b[0;34m(model, filenameModel, batchSize)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sparse_categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     model.fit(image[:nVal], charOutput[:nVal], epochs=50, batch_size=batchSize,\n\u001b[0;32m---> 20\u001b[0;31m               validation_data=(image[nVal:nFrac], charOutput[nVal:nFrac]), shuffle=True, callbacks=callbacks)\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilenameModel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mlearning/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    778\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m           \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m           steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/miniconda3/envs/mlearning/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mlearning/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3292\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m~/miniconda3/envs/mlearning/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizeHyperParameter(createModel1, '../models/KMNIST1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         image:  5.2 GiB\n",
      "                    charOutput:  1.3 MiB\n",
      "                   unicodeData: 687.4 KiB\n",
      "                          _iii:  9.3 KiB\n",
      "                           _i4:  9.3 KiB\n",
      "                           _i7:  587.0 B\n",
      "                           _i3:  575.0 B\n",
      "                           _i1:  330.0 B\n",
      "                           _i2:  330.0 B\n",
      "                           _oh:  240.0 B\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "def sizeof_fmt(num, suffix='B'):\n",
    "    ''' by Fred Cirera,  https://stackoverflow.com/a/1094933/1870254, modified'''\n",
    "    for unit in ['','Ki','Mi','Gi','Ti','Pi','Ei','Zi']:\n",
    "        if abs(num) < 1024.0:\n",
    "            return \"%3.1f %s%s\" % (num, unit, suffix)\n",
    "        num /= 1024.0\n",
    "    return \"%.1f %s%s\" % (num, 'Yi', suffix)\n",
    "\n",
    "for name, size in sorted(((name, sys.getsizeof(value)) for name, value in locals().items()),\n",
    "                         key= lambda x: -x[1])[:10]:\n",
    "    print(\"{:>30}: {:>8}\".format(name, sizeof_fmt(size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(683464, 32, 32, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5339.5625"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.nbytes/1024/1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.float16"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.float16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
