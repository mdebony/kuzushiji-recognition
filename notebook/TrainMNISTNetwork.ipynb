{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "\n",
    "dataRep = '../data/'\n",
    "scriptRep = '../kuzushiji_recognition/'\n",
    "\n",
    "# some_file.py\n",
    "import sys\n",
    "# insert at 1, 0 is the script path (or '' in REPL)\n",
    "sys.path.insert(1, scriptRep)\n",
    "import progressBar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "683464 (32, 32, 1) 478424 580944\n"
     ]
    }
   ],
   "source": [
    "testFrac = 0.15\n",
    "valFrac = 0.15\n",
    "\n",
    "unicodeData = pd.read_csv(dataRep+'unicode_translation.csv')\n",
    "\n",
    "raw = np.load('../data/dataset/caracterClassificationFull.npz')\n",
    "image = np.expand_dims(raw['image'], 3).copy()\n",
    "charOutput = raw['characterClass'].copy()\n",
    "del raw\n",
    "\n",
    "index = np.arange(image.shape[0])\n",
    "np.random.shuffle(index)\n",
    "image = image[index]/255.0\n",
    "charOutput = charOutput[index]\n",
    "del index\n",
    "\n",
    "nFrac = int(image.shape[0]*(1.-testFrac))\n",
    "nVal = int(image.shape[0]*(1.-testFrac-valFrac))\n",
    "print(image.shape[0], image.shape[1:], nVal, nFrac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainAndEvaluateModel(model, filenameModel, batchSize):\n",
    "    \n",
    "    checkpoint = keras.callbacks.ModelCheckpoint(filepath=filenameModel,\n",
    "                                                 monitor='val_loss',\n",
    "                                                 verbose=0,\n",
    "                                                 save_best_only=True,\n",
    "                                                 mode='auto', period=1)\n",
    "    history = keras.callbacks.History()\n",
    "    reduceLR = keras.callbacks.ReduceLROnPlateau(monitor='val_loss',\n",
    "                                                 factor=0.1, patience=2,\n",
    "                                                 verbose=0,\n",
    "                                                 mode='auto')\n",
    "    earlyStop = keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                              min_delta=1e-7, patience=5,\n",
    "                                              verbose=0, mode='auto')\n",
    "    callbacks = [checkpoint, history, reduceLR, earlyStop]\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(image[:nVal], charOutput[:nVal], epochs=50, batch_size=batchSize,\n",
    "              validation_data=(image[nVal:nFrac], charOutput[nVal:nFrac]), shuffle=True, callbacks=callbacks)\n",
    "    \n",
    "    model = keras.models.load_model(filenameModel)\n",
    "    test_loss, test_acc = model.evaluate(image[nVal:nFrac], charOutput[nVal:nFrac])\n",
    "    \n",
    "    return test_loss\n",
    "\n",
    "\n",
    "def optimizeHyperParameter(funcCreateModel, filenameModel, dropoutLimit=(0,20), batchSizeLimit=(0,10), convolutionLayerLimit=(2,10), denseLayerLimit=(2,10), maxIter=30):\n",
    "    \n",
    "    i=0\n",
    "    stop=False\n",
    "    curentParam = [5, 8, 7, 8] # (dropout, batchsize, convolution, dense)\n",
    "    testedParam = np.zeros((dropoutLimit[1]+1, batchSizeLimit[1]+1, convolutionLayerLimit[1]+1, denseLayerLimit[1]+1), dtype=np.bool)\n",
    "    \n",
    "    stdLoss = trainAndEvaluateModel(funcCreateModel(curentParam[0]/20., 2**(curentParam[2]), 2**(curentParam[3])), filenameModel, 2**(curentParam[1]))\n",
    "    testedParam[curentParam[0], curentParam[1], curentParam[2], curentParam[3]] = True\n",
    "    \n",
    "    while (i<maxIter) and not stop:\n",
    "        i+=1\n",
    "        stop=True\n",
    "        \n",
    "        if (curentParam[0]-1) >= dropoutLimit[0] and not testedParam[curentParam[0]-1, curentParam[1], curentParam[2], curentParam[3]]:\n",
    "            print(\"Test dropout down\")\n",
    "            testLoss = trainAndEvaluateModel(funcCreateModel(float(curentParam[0]-1)/20., 2**(curentParam[2]), 2**(curentParam[3])),\n",
    "                                             'temp.h5', 2**(curentParam[1]))\n",
    "            testedParam[curentParam[0]-1, curentParam[1], curentParam[2], curentParam[3]] = True\n",
    "            \n",
    "            if testLoss < stdLoss:\n",
    "                stop=False\n",
    "                stdLoss = testLoss\n",
    "                curentParam[0] -= 1\n",
    "                os.system(\"cp temp.h5 \"+filenameModel)\n",
    "                print(\"New param set\", curentParam)\n",
    "            \n",
    "        if (curentParam[0]+1) <= dropoutLimit[1] and not testedParam[curentParam[0]+1, curentParam[1], curentParam[2], curentParam[3]]:\n",
    "            print(\"Test dropout up\")\n",
    "            testLoss = trainAndEvaluateModel(funcCreateModel(float(curentParam[0]+1)/20., 2**(curentParam[2]), 2**(curentParam[3])),\n",
    "                                             'temp.h5', 2**(curentParam[1]))\n",
    "            testedParam[curentParam[0]+1, curentParam[1], curentParam[2], curentParam[3]] = True\n",
    "            \n",
    "            if testLoss < stdLoss:\n",
    "                stop=False\n",
    "                stdLoss = testLoss\n",
    "                curentParam[0] += 1\n",
    "                os.system(\"cp temp.h5 \"+filenameModel)\n",
    "                print(\"New param set\", curentParam)\n",
    "                \n",
    "                \n",
    "        if (curentParam[1]-1) >= batchSizeLimit[0] and not testedParam[curentParam[0], curentParam[1]-1, curentParam[2], curentParam[3]]:\n",
    "            print(\"Test batchsize down\")\n",
    "            testLoss = trainAndEvaluateModel(funcCreateModel(curentParam[0]/20., 2**(curentParam[2]), 2**(curentParam[3])),\n",
    "                                             'temp.h5', 2**(curentParam[1]-1))\n",
    "            testedParam[curentParam[0], curentParam[1]-1, curentParam[2], curentParam[3]] = True\n",
    "            \n",
    "            if testLoss < stdLoss:\n",
    "                stop=False\n",
    "                stdLoss = testLoss\n",
    "                curentParam[1] -= 1\n",
    "                os.system(\"cp temp.h5 \"+filenameModel)\n",
    "                print(\"New param set\", curentParam)\n",
    "            \n",
    "        if (curentParam[1]+1) <= batchSizeLimit[1] and not testedParam[curentParam[0], curentParam[1]+1, curentParam[2], curentParam[3]]:\n",
    "            print(\"Test batchsize up\")\n",
    "            testLoss = trainAndEvaluateModel(funcCreateModel(curentParam[0]/20., 2**(curentParam[2]), 2**(curentParam[3])),\n",
    "                                             'temp.h5', 2**(curentParam[1]+1))\n",
    "            testedParam[curentParam[0], curentParam[1]+1, curentParam[2], curentParam[3]] = True\n",
    "            \n",
    "            if testLoss < stdLoss:\n",
    "                stop=False\n",
    "                stdLoss = testLoss\n",
    "                curentParam[1] += 1\n",
    "                os.system(\"cp temp.h5 \"+filenameModel)\n",
    "                print(\"New param set\", curentParam)\n",
    "                \n",
    "        if (curentParam[2]-1) >= convolutionLayerLimit[0] and not testedParam[curentParam[0], curentParam[1], curentParam[2]-1, curentParam[3]]:\n",
    "            print(\"Test convolution down\")\n",
    "            testLoss = trainAndEvaluateModel(funcCreateModel(curentParam[0]/20., 2**(curentParam[2]-1), 2**(curentParam[3])),\n",
    "                                             'temp.h5', 2**(curentParam[1]))\n",
    "            testedParam[curentParam[0], curentParam[1], curentParam[2]-1, curentParam[3]] = True\n",
    "            \n",
    "            if testLoss < stdLoss:\n",
    "                stop=False\n",
    "                stdLoss = testLoss\n",
    "                curentParam[2] -= 1\n",
    "                os.system(\"cp temp.h5 \"+filenameModel)\n",
    "                print(\"New param set\", curentParam)\n",
    "            \n",
    "        if (curentParam[2]+1) <= convolutionLayerLimit[1] and not testedParam[curentParam[0]-1, curentParam[1], curentParam[2]+1, curentParam[3]]:\n",
    "            print(\"Test convolution up\")\n",
    "            testLoss = trainAndEvaluateModel(funcCreateModel(curentParam[0]/20., 2**(curentParam[2]+1), 2**(curentParam[3])),\n",
    "                                             'temp.h5', 2**(curentParam[1]))\n",
    "            testedParam[curentParam[0], curentParam[1], curentParam[2]+1, curentParam[3]] = True\n",
    "            \n",
    "            if testLoss < stdLoss:\n",
    "                stop=False\n",
    "                stdLoss = testLoss\n",
    "                curentParam[2] += 1\n",
    "                os.system(\"cp temp.h5 \"+filenameModel)\n",
    "                print(\"New param set\", curentParam)\n",
    "                \n",
    "        if (curentParam[3]-1) >= denseLayerLimit[0] and not testedParam[curentParam[0]-1, curentParam[1], curentParam[2], curentParam[3]-1]:\n",
    "            print(\"Test dense down\")\n",
    "            testLoss = trainAndEvaluateModel(funcCreateModel(curentParam[0]/20., 2**(curentParam[2]), 2**(curentParam[3]-1)),\n",
    "                                             'temp.h5', 2**(curentParam[1]))\n",
    "            testedParam[curentParam[0], curentParam[1], curentParam[2], curentParam[3]-1] = True\n",
    "            \n",
    "            if testLoss < stdLoss:\n",
    "                stop=False\n",
    "                stdLoss = testLoss\n",
    "                curentParam[3] -= 1\n",
    "                os.system(\"cp temp.h5 \"+filenameModel)\n",
    "                print(\"New param set\", curentParam)\n",
    "            \n",
    "        if (curentParam[3]+1) <= denseLayerLimit[1] and not testedParam[curentParam[0]-1, curentParam[1], curentParam[2], curentParam[3]+1]:\n",
    "            print(\"Test dense up\")\n",
    "            testLoss = trainAndEvaluateModel(funcCreateModel(curentParam[0]/20., 2**(curentParam[2]), 2**(curentParam[3]+1)),\n",
    "                                             'temp.h5', 2**(curentParam[1]))\n",
    "            testedParam[curentParam[0], curentParam[1], curentParam[2], curentParam[3]+1] = True\n",
    "            \n",
    "            if testLoss < stdLoss:\n",
    "                stop=False\n",
    "                stdLoss = testLoss\n",
    "                curentParam[3] += 1\n",
    "                os.system(\"cp temp.h5 \"+filenameModel)\n",
    "                print(\"New param set\", curentParam)\n",
    "                \n",
    "    print('Dropout :', curentParam[0])\n",
    "    print('Batch Size :', 2**curentParam[1])\n",
    "    print('Convolutional layer :', 2**curentParam[2])\n",
    "    print('Dense Layer :', 2**curentParam[3])\n",
    "    os.system(\"rm temp.h5\")\n",
    "    \n",
    "    print(\"Nb iteration\", i, \"/\", maxIter)\n",
    "    print(\"Nb case tested\", np.sum(testedParam), \"/\", np.sum(np.ones(testedParam.shape, dtype=np.bool)))\n",
    "        \n",
    "def createModel1(dropoutRate, convLayer, denseLayer):\n",
    "    \n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Conv2D(convLayer, (3, 3), activation='relu', input_shape=image.shape[1:]))\n",
    "    model.add(keras.layers.SpatialDropout2D(dropoutRate))\n",
    "    model.add(keras.layers.Conv2D(convLayer, (3, 3), activation='relu'))\n",
    "    model.add(keras.layers.SpatialDropout2D(dropoutRate))\n",
    "    model.add(keras.layers.MaxPooling2D((2, 2)))\n",
    "    model.add(keras.layers.Conv2D(convLayer*2, (3, 3), activation='relu'))\n",
    "    model.add(keras.layers.SpatialDropout2D(dropoutRate))\n",
    "    model.add(keras.layers.Conv2D(convLayer*2, (3, 3), activation='relu'))\n",
    "    model.add(keras.layers.SpatialDropout2D(dropoutRate))\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(denseLayer, activation='relu'))\n",
    "    model.add(keras.layers.Dropout(dropoutRate))\n",
    "    model.add(keras.layers.Dense(len(unicodeData), activation='softmax'))\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0909 01:20:21.898675  3672 deprecation.py:506] From C:\\Users\\bapti\\Miniconda3\\envs\\env\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0909 01:20:22.158014  3672 callbacks.py:875] `period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 478424 samples, validate on 102520 samples\n",
      "Epoch 1/50\n",
      "478424/478424 [==============================] - 66s 137us/sample - loss: 2.8273 - acc: 0.5022 - val_loss: 1.6445 - val_acc: 0.7051\n",
      "Epoch 2/50\n",
      "478424/478424 [==============================] - 64s 133us/sample - loss: 1.8363 - acc: 0.6462 - val_loss: 1.3269 - val_acc: 0.7548\n",
      "Epoch 3/50\n",
      "478424/478424 [==============================] - 64s 133us/sample - loss: 1.5887 - acc: 0.6815 - val_loss: 1.1710 - val_acc: 0.7838\n",
      "Epoch 4/50\n",
      "478424/478424 [==============================] - 64s 134us/sample - loss: 1.4486 - acc: 0.7016 - val_loss: 1.0969 - val_acc: 0.7954\n",
      "Epoch 5/50\n",
      "478424/478424 [==============================] - 64s 134us/sample - loss: 1.3544 - acc: 0.7157 - val_loss: 1.0247 - val_acc: 0.8068\n",
      "Epoch 6/50\n",
      "478424/478424 [==============================] - 64s 134us/sample - loss: 1.2892 - acc: 0.7261 - val_loss: 0.9831 - val_acc: 0.8137\n",
      "Epoch 7/50\n",
      "478424/478424 [==============================] - 64s 134us/sample - loss: 1.2372 - acc: 0.7335 - val_loss: 0.9381 - val_acc: 0.8213\n",
      "Epoch 8/50\n",
      "478424/478424 [==============================] - 64s 134us/sample - loss: 1.1986 - acc: 0.7391 - val_loss: 0.9241 - val_acc: 0.8234\n",
      "Epoch 9/50\n",
      "478424/478424 [==============================] - 64s 134us/sample - loss: 1.1672 - acc: 0.7436 - val_loss: 0.8983 - val_acc: 0.8278\n",
      "Epoch 10/50\n",
      "478424/478424 [==============================] - 63s 132us/sample - loss: 1.1425 - acc: 0.7477 - val_loss: 0.8792 - val_acc: 0.8305\n",
      "Epoch 11/50\n",
      "478424/478424 [==============================] - 63s 131us/sample - loss: 1.1174 - acc: 0.7515 - val_loss: 0.8688 - val_acc: 0.8321\n",
      "Epoch 12/50\n",
      "478424/478424 [==============================] - 63s 131us/sample - loss: 1.1002 - acc: 0.7540 - val_loss: 0.8633 - val_acc: 0.8329\n",
      "Epoch 13/50\n",
      "478424/478424 [==============================] - 63s 131us/sample - loss: 1.0878 - acc: 0.7557 - val_loss: 0.8463 - val_acc: 0.8372\n",
      "Epoch 14/50\n",
      "478424/478424 [==============================] - 63s 131us/sample - loss: 1.0740 - acc: 0.7580 - val_loss: 0.8583 - val_acc: 0.8341\n",
      "Epoch 15/50\n",
      "478424/478424 [==============================] - 63s 131us/sample - loss: 1.0665 - acc: 0.7592 - val_loss: 0.8136 - val_acc: 0.8413\n",
      "Epoch 16/50\n",
      "478424/478424 [==============================] - 63s 131us/sample - loss: 1.0593 - acc: 0.7607 - val_loss: 0.8262 - val_acc: 0.8413\n",
      "Epoch 17/50\n",
      "478424/478424 [==============================] - 63s 131us/sample - loss: 1.0553 - acc: 0.7602 - val_loss: 0.8165 - val_acc: 0.8405\n",
      "Epoch 18/50\n",
      "478424/478424 [==============================] - 63s 131us/sample - loss: 0.9492 - acc: 0.7814 - val_loss: 0.7863 - val_acc: 0.8483\n",
      "Epoch 19/50\n",
      "478424/478424 [==============================] - 63s 131us/sample - loss: 0.9243 - acc: 0.7863 - val_loss: 0.7809 - val_acc: 0.8502\n",
      "Epoch 20/50\n",
      "478424/478424 [==============================] - 63s 131us/sample - loss: 0.9103 - acc: 0.7894 - val_loss: 0.7750 - val_acc: 0.8512\n",
      "Epoch 21/50\n",
      "478424/478424 [==============================] - 63s 131us/sample - loss: 0.9044 - acc: 0.7902 - val_loss: 0.7729 - val_acc: 0.8519\n",
      "Epoch 22/50\n",
      "478424/478424 [==============================] - 63s 131us/sample - loss: 0.8921 - acc: 0.7919 - val_loss: 0.7666 - val_acc: 0.8525\n",
      "Epoch 23/50\n",
      "478424/478424 [==============================] - 63s 132us/sample - loss: 0.8880 - acc: 0.7934 - val_loss: 0.7647 - val_acc: 0.8542\n",
      "Epoch 24/50\n",
      "478424/478424 [==============================] - 65s 135us/sample - loss: 0.8822 - acc: 0.7946 - val_loss: 0.7606 - val_acc: 0.8535\n",
      "Epoch 25/50\n",
      "478424/478424 [==============================] - 64s 134us/sample - loss: 0.8760 - acc: 0.7955 - val_loss: 0.7595 - val_acc: 0.8548\n",
      "Epoch 26/50\n",
      "478424/478424 [==============================] - 64s 134us/sample - loss: 0.8733 - acc: 0.7967 - val_loss: 0.7574 - val_acc: 0.8548\n",
      "Epoch 27/50\n",
      "478424/478424 [==============================] - 63s 132us/sample - loss: 0.8665 - acc: 0.7977 - val_loss: 0.7572 - val_acc: 0.8556\n",
      "Epoch 28/50\n",
      "478424/478424 [==============================] - 63s 131us/sample - loss: 0.8658 - acc: 0.7976 - val_loss: 0.7565 - val_acc: 0.8554\n",
      "Epoch 29/50\n",
      "478424/478424 [==============================] - 63s 131us/sample - loss: 0.8652 - acc: 0.7982 - val_loss: 0.7567 - val_acc: 0.8553\n",
      "Epoch 30/50\n",
      "478424/478424 [==============================] - 63s 131us/sample - loss: 0.8579 - acc: 0.7985 - val_loss: 0.7537 - val_acc: 0.8558\n",
      "Epoch 31/50\n",
      "478424/478424 [==============================] - 63s 131us/sample - loss: 0.8560 - acc: 0.7996 - val_loss: 0.7486 - val_acc: 0.8564\n",
      "Epoch 32/50\n",
      "478424/478424 [==============================] - 63s 131us/sample - loss: 0.8550 - acc: 0.8001 - val_loss: 0.7457 - val_acc: 0.8571\n",
      "Epoch 33/50\n",
      "478424/478424 [==============================] - 63s 131us/sample - loss: 0.8484 - acc: 0.8005 - val_loss: 0.7508 - val_acc: 0.8564\n",
      "Epoch 34/50\n",
      "478424/478424 [==============================] - 63s 131us/sample - loss: 0.8472 - acc: 0.8008 - val_loss: 0.7472 - val_acc: 0.8574\n",
      "Epoch 35/50\n",
      "478424/478424 [==============================] - 63s 131us/sample - loss: 0.8369 - acc: 0.8026 - val_loss: 0.7447 - val_acc: 0.8578\n",
      "Epoch 36/50\n",
      "478424/478424 [==============================] - 63s 131us/sample - loss: 0.8360 - acc: 0.8032 - val_loss: 0.7444 - val_acc: 0.8581\n",
      "Epoch 37/50\n",
      "478424/478424 [==============================] - 63s 131us/sample - loss: 0.8334 - acc: 0.8034 - val_loss: 0.7439 - val_acc: 0.8581\n",
      "Epoch 38/50\n",
      "478424/478424 [==============================] - 63s 132us/sample - loss: 0.8329 - acc: 0.8035 - val_loss: 0.7426 - val_acc: 0.8585\n",
      "Epoch 39/50\n",
      "478424/478424 [==============================] - 63s 131us/sample - loss: 0.8328 - acc: 0.8041 - val_loss: 0.7437 - val_acc: 0.8582\n",
      "Epoch 40/50\n",
      "478424/478424 [==============================] - 63s 131us/sample - loss: 0.8308 - acc: 0.8044 - val_loss: 0.7433 - val_acc: 0.8580\n",
      "Epoch 41/50\n",
      "478424/478424 [==============================] - 63s 131us/sample - loss: 0.8283 - acc: 0.8047 - val_loss: 0.7434 - val_acc: 0.8581\n",
      "Epoch 42/50\n",
      "478424/478424 [==============================] - 63s 131us/sample - loss: 0.8295 - acc: 0.8042 - val_loss: 0.7431 - val_acc: 0.8581\n",
      "Epoch 43/50\n",
      "478424/478424 [==============================] - 63s 131us/sample - loss: 0.8320 - acc: 0.8040 - val_loss: 0.7431 - val_acc: 0.8581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0909 02:05:43.337551  3672 deprecation.py:506] From C:\\Users\\bapti\\Miniconda3\\envs\\env\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0909 02:05:43.338512  3672 deprecation.py:506] From C:\\Users\\bapti\\Miniconda3\\envs\\env\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102520/102520 [==============================] - 8s 79us/sample - loss: 0.7426 - acc: 0.8585\n",
      "Test dropout down\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0909 02:05:52.906609  3672 callbacks.py:875] `period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 478424 samples, validate on 102520 samples\n",
      "Epoch 1/50\n",
      "478424/478424 [==============================] - 64s 134us/sample - loss: 2.6906 - acc: 0.5241 - val_loss: 1.5337 - val_acc: 0.7238\n",
      "Epoch 2/50\n",
      "478424/478424 [==============================] - 64s 133us/sample - loss: 1.6641 - acc: 0.6764 - val_loss: 1.2228 - val_acc: 0.7763\n",
      "Epoch 3/50\n",
      "478424/478424 [==============================] - 64s 134us/sample - loss: 1.4083 - acc: 0.7136 - val_loss: 1.0645 - val_acc: 0.8019\n",
      "Epoch 4/50\n",
      "478424/478424 [==============================] - 64s 133us/sample - loss: 1.2674 - acc: 0.7340 - val_loss: 0.9677 - val_acc: 0.8182\n",
      "Epoch 5/50\n",
      "478424/478424 [==============================] - 64s 134us/sample - loss: 1.1704 - acc: 0.7487 - val_loss: 0.9099 - val_acc: 0.8278\n",
      "Epoch 6/50\n",
      "478424/478424 [==============================] - 64s 134us/sample - loss: 1.0961 - acc: 0.7599 - val_loss: 0.8657 - val_acc: 0.8353\n",
      "Epoch 7/50\n",
      "478424/478424 [==============================] - 64s 134us/sample - loss: 1.0446 - acc: 0.7687 - val_loss: 0.8368 - val_acc: 0.8399\n",
      "Epoch 8/50\n",
      "478424/478424 [==============================] - 64s 134us/sample - loss: 1.0010 - acc: 0.7743 - val_loss: 0.8035 - val_acc: 0.8455\n",
      "Epoch 9/50\n",
      "478424/478424 [==============================] - 64s 134us/sample - loss: 0.9667 - acc: 0.7807 - val_loss: 0.7917 - val_acc: 0.8475\n",
      "Epoch 10/50\n",
      "478424/478424 [==============================] - 64s 134us/sample - loss: 0.9372 - acc: 0.7848 - val_loss: 0.7799 - val_acc: 0.8495\n",
      "Epoch 11/50\n",
      "478424/478424 [==============================] - 64s 134us/sample - loss: 0.9136 - acc: 0.7888 - val_loss: 0.7566 - val_acc: 0.8535\n",
      "Epoch 12/50\n",
      "478424/478424 [==============================] - 64s 134us/sample - loss: 0.8955 - acc: 0.7916 - val_loss: 0.7441 - val_acc: 0.8557\n",
      "Epoch 13/50\n",
      "478424/478424 [==============================] - 64s 134us/sample - loss: 0.8779 - acc: 0.7946 - val_loss: 0.7344 - val_acc: 0.8566\n",
      "Epoch 14/50\n",
      "478424/478424 [==============================] - 64s 134us/sample - loss: 0.8660 - acc: 0.7956 - val_loss: 0.7241 - val_acc: 0.8574\n",
      "Epoch 15/50\n",
      "478424/478424 [==============================] - 64s 134us/sample - loss: 0.8528 - acc: 0.7977 - val_loss: 0.7180 - val_acc: 0.8595\n",
      "Epoch 16/50\n",
      "478424/478424 [==============================] - 64s 134us/sample - loss: 0.8449 - acc: 0.7986 - val_loss: 0.7303 - val_acc: 0.8586\n",
      "Epoch 17/50\n",
      "478424/478424 [==============================] - 64s 134us/sample - loss: 0.8322 - acc: 0.8009 - val_loss: 0.7197 - val_acc: 0.8586\n",
      "Epoch 18/50\n",
      "478424/478424 [==============================] - 64s 134us/sample - loss: 0.7289 - acc: 0.8228 - val_loss: 0.6852 - val_acc: 0.8686\n",
      "Epoch 19/50\n",
      "478424/478424 [==============================] - 64s 134us/sample - loss: 0.7038 - acc: 0.8281 - val_loss: 0.6748 - val_acc: 0.8709\n",
      "Epoch 20/50\n",
      "478424/478424 [==============================] - 64s 134us/sample - loss: 0.6930 - acc: 0.8302 - val_loss: 0.6740 - val_acc: 0.8713\n",
      "Epoch 21/50\n",
      "478424/478424 [==============================] - 64s 134us/sample - loss: 0.6858 - acc: 0.8315 - val_loss: 0.6705 - val_acc: 0.8722\n",
      "Epoch 22/50\n",
      "478424/478424 [==============================] - 64s 134us/sample - loss: 0.6802 - acc: 0.8327 - val_loss: 0.6699 - val_acc: 0.8724\n",
      "Epoch 23/50\n",
      "478424/478424 [==============================] - 64s 134us/sample - loss: 0.6768 - acc: 0.8339 - val_loss: 0.6693 - val_acc: 0.8721\n",
      "Epoch 24/50\n",
      "478424/478424 [==============================] - 64s 134us/sample - loss: 0.6692 - acc: 0.8349 - val_loss: 0.6654 - val_acc: 0.8738\n",
      "Epoch 25/50\n",
      "478424/478424 [==============================] - 64s 134us/sample - loss: 0.6661 - acc: 0.8361 - val_loss: 0.6631 - val_acc: 0.8735\n",
      "Epoch 26/50\n",
      "478424/478424 [==============================] - 64s 134us/sample - loss: 0.6620 - acc: 0.8365 - val_loss: 0.6621 - val_acc: 0.8740\n",
      "Epoch 27/50\n",
      "478424/478424 [==============================] - 64s 134us/sample - loss: 0.6587 - acc: 0.8374 - val_loss: 0.6571 - val_acc: 0.8742\n",
      "Epoch 28/50\n",
      "478424/478424 [==============================] - 64s 134us/sample - loss: 0.6552 - acc: 0.8376 - val_loss: 0.6571 - val_acc: 0.8746\n",
      "Epoch 29/50\n",
      "478424/478424 [==============================] - 64s 134us/sample - loss: 0.6508 - acc: 0.8380 - val_loss: 0.6592 - val_acc: 0.8746\n",
      "Epoch 30/50\n",
      "478424/478424 [==============================] - 64s 134us/sample - loss: 0.6421 - acc: 0.8406 - val_loss: 0.6564 - val_acc: 0.8750\n",
      "Epoch 31/50\n",
      "478424/478424 [==============================] - 64s 134us/sample - loss: 0.6403 - acc: 0.8414 - val_loss: 0.6570 - val_acc: 0.8751\n",
      "Epoch 32/50\n",
      "478424/478424 [==============================] - 64s 134us/sample - loss: 0.6403 - acc: 0.8406 - val_loss: 0.6558 - val_acc: 0.8756\n",
      "Epoch 33/50\n",
      "478424/478424 [==============================] - 64s 134us/sample - loss: 0.6401 - acc: 0.8413 - val_loss: 0.6556 - val_acc: 0.8755\n",
      "Epoch 34/50\n",
      "478424/478424 [==============================] - 64s 134us/sample - loss: 0.6353 - acc: 0.8421 - val_loss: 0.6562 - val_acc: 0.8754\n",
      "Epoch 35/50\n",
      "478424/478424 [==============================] - 64s 134us/sample - loss: 0.6376 - acc: 0.8417 - val_loss: 0.6549 - val_acc: 0.8754\n",
      "Epoch 36/50\n",
      "478424/478424 [==============================] - 64s 134us/sample - loss: 0.6381 - acc: 0.8413 - val_loss: 0.6535 - val_acc: 0.8754\n",
      "Epoch 37/50\n",
      "478424/478424 [==============================] - 64s 134us/sample - loss: 0.6341 - acc: 0.8425 - val_loss: 0.6534 - val_acc: 0.8755\n",
      "Epoch 38/50\n",
      "478424/478424 [==============================] - 64s 134us/sample - loss: 0.6373 - acc: 0.8421 - val_loss: 0.6533 - val_acc: 0.8755\n",
      "Epoch 39/50\n",
      "478424/478424 [==============================] - 64s 134us/sample - loss: 0.6360 - acc: 0.8419 - val_loss: 0.6537 - val_acc: 0.8756\n",
      "Epoch 40/50\n",
      "478424/478424 [==============================] - 64s 134us/sample - loss: 0.6353 - acc: 0.8417 - val_loss: 0.6539 - val_acc: 0.8754\n",
      "Epoch 41/50\n",
      "478424/478424 [==============================] - 64s 134us/sample - loss: 0.6335 - acc: 0.8423 - val_loss: 0.6536 - val_acc: 0.8756\n",
      "Epoch 42/50\n",
      "478424/478424 [==============================] - 64s 134us/sample - loss: 0.6332 - acc: 0.8429 - val_loss: 0.6534 - val_acc: 0.8756\n",
      "Epoch 43/50\n",
      "478424/478424 [==============================] - 64s 134us/sample - loss: 0.6325 - acc: 0.8426 - val_loss: 0.6534 - val_acc: 0.8756\n",
      "102520/102520 [==============================] - 8s 81us/sample - loss: 0.6533 - acc: 0.8755\n",
      "New param set [5, 6, 4, 8]\n",
      "Test batchsize down\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0909 02:51:54.198692  3672 callbacks.py:875] `period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 478424 samples, validate on 102520 samples\n",
      "Epoch 1/50\n",
      "478424/478424 [==============================] - 103s 216us/sample - loss: 2.6708 - acc: 0.5374 - val_loss: 1.6579 - val_acc: 0.7111\n",
      "Epoch 2/50\n",
      "478424/478424 [==============================] - 103s 215us/sample - loss: 1.8150 - acc: 0.6622 - val_loss: 1.3730 - val_acc: 0.7546\n",
      "Epoch 3/50\n",
      "478424/478424 [==============================] - 103s 215us/sample - loss: 1.6030 - acc: 0.6925 - val_loss: 1.2397 - val_acc: 0.7768\n",
      "Epoch 4/50\n",
      "478424/478424 [==============================] - 103s 215us/sample - loss: 1.4820 - acc: 0.7094 - val_loss: 1.1661 - val_acc: 0.7891\n",
      "Epoch 5/50\n",
      "478424/478424 [==============================] - 103s 215us/sample - loss: 1.4098 - acc: 0.7196 - val_loss: 1.1166 - val_acc: 0.7952\n",
      "Epoch 6/50\n",
      "478424/478424 [==============================] - 103s 215us/sample - loss: 1.3632 - acc: 0.7258 - val_loss: 1.0644 - val_acc: 0.8019\n",
      "Epoch 7/50\n",
      "478424/478424 [==============================] - 103s 214us/sample - loss: 1.3292 - acc: 0.7304 - val_loss: 1.0280 - val_acc: 0.8100\n",
      "Epoch 8/50\n",
      "478424/478424 [==============================] - 103s 215us/sample - loss: 1.3026 - acc: 0.7342 - val_loss: 1.0435 - val_acc: 0.8068\n",
      "Epoch 9/50\n",
      "478424/478424 [==============================] - 103s 215us/sample - loss: 1.3068 - acc: 0.7326 - val_loss: 1.0104 - val_acc: 0.8110\n",
      "Epoch 10/50\n",
      "478424/478424 [==============================] - 103s 215us/sample - loss: 1.2813 - acc: 0.7359 - val_loss: 0.9818 - val_acc: 0.8176\n",
      "Epoch 11/50\n",
      "478424/478424 [==============================] - 103s 215us/sample - loss: 1.2670 - acc: 0.7377 - val_loss: 1.0051 - val_acc: 0.8118\n",
      "Epoch 12/50\n",
      "478424/478424 [==============================] - 103s 215us/sample - loss: 1.2735 - acc: 0.7361 - val_loss: 0.9866 - val_acc: 0.8155\n",
      "Epoch 13/50\n",
      "478424/478424 [==============================] - 103s 215us/sample - loss: 1.0980 - acc: 0.7682 - val_loss: 0.9159 - val_acc: 0.8312\n",
      "Epoch 14/50\n",
      "478424/478424 [==============================] - 103s 215us/sample - loss: 1.0589 - acc: 0.7759 - val_loss: 0.9004 - val_acc: 0.8339\n",
      "Epoch 15/50\n",
      "478424/478424 [==============================] - 103s 215us/sample - loss: 1.0407 - acc: 0.7784 - val_loss: 0.8918 - val_acc: 0.8353\n",
      "Epoch 16/50\n",
      "478424/478424 [==============================] - 103s 215us/sample - loss: 1.0258 - acc: 0.7819 - val_loss: 0.8845 - val_acc: 0.8370\n",
      "Epoch 17/50\n",
      "478424/478424 [==============================] - 103s 215us/sample - loss: 1.0162 - acc: 0.7844 - val_loss: 0.8780 - val_acc: 0.8374\n",
      "Epoch 18/50\n",
      "478424/478424 [==============================] - 103s 215us/sample - loss: 1.0078 - acc: 0.7859 - val_loss: 0.8727 - val_acc: 0.8392\n",
      "Epoch 19/50\n",
      "478424/478424 [==============================] - 103s 215us/sample - loss: 0.9979 - acc: 0.7880 - val_loss: 0.8680 - val_acc: 0.8404\n",
      "Epoch 20/50\n",
      "478424/478424 [==============================] - 103s 215us/sample - loss: 0.9936 - acc: 0.7879 - val_loss: 0.8670 - val_acc: 0.8402\n",
      "Epoch 21/50\n",
      "478424/478424 [==============================] - 103s 215us/sample - loss: 0.9869 - acc: 0.7895 - val_loss: 0.8612 - val_acc: 0.8411\n",
      "Epoch 22/50\n",
      "478424/478424 [==============================] - 103s 215us/sample - loss: 0.9821 - acc: 0.7902 - val_loss: 0.8586 - val_acc: 0.8411\n",
      "Epoch 23/50\n",
      "478424/478424 [==============================] - 103s 215us/sample - loss: 0.9733 - acc: 0.7913 - val_loss: 0.8520 - val_acc: 0.8420\n",
      "Epoch 24/50\n",
      "478424/478424 [==============================] - 103s 215us/sample - loss: 0.9692 - acc: 0.7918 - val_loss: 0.8520 - val_acc: 0.8430\n",
      "Epoch 25/50\n",
      "478424/478424 [==============================] - 103s 215us/sample - loss: 0.9641 - acc: 0.7935 - val_loss: 0.8476 - val_acc: 0.8432\n",
      "Epoch 26/50\n",
      "478424/478424 [==============================] - 103s 215us/sample - loss: 0.9617 - acc: 0.7935 - val_loss: 0.8472 - val_acc: 0.8434\n",
      "Epoch 27/50\n",
      "478424/478424 [==============================] - 103s 215us/sample - loss: 0.9559 - acc: 0.7945 - val_loss: 0.8450 - val_acc: 0.8447\n",
      "Epoch 28/50\n",
      "478424/478424 [==============================] - 103s 215us/sample - loss: 0.9527 - acc: 0.7948 - val_loss: 0.8398 - val_acc: 0.8444\n",
      "Epoch 29/50\n",
      "478424/478424 [==============================] - 103s 215us/sample - loss: 0.9486 - acc: 0.7957 - val_loss: 0.8386 - val_acc: 0.8448\n",
      "Epoch 30/50\n",
      "478424/478424 [==============================] - 103s 215us/sample - loss: 0.9427 - acc: 0.7963 - val_loss: 0.8340 - val_acc: 0.8452\n",
      "Epoch 31/50\n",
      "478424/478424 [==============================] - 103s 215us/sample - loss: 0.9391 - acc: 0.7966 - val_loss: 0.8315 - val_acc: 0.8461\n",
      "Epoch 32/50\n",
      "478424/478424 [==============================] - 103s 215us/sample - loss: 0.9362 - acc: 0.7973 - val_loss: 0.8294 - val_acc: 0.8467\n",
      "Epoch 33/50\n",
      "478424/478424 [==============================] - 103s 215us/sample - loss: 0.9328 - acc: 0.7978 - val_loss: 0.8252 - val_acc: 0.8475\n",
      "Epoch 34/50\n",
      "478424/478424 [==============================] - 103s 215us/sample - loss: 0.9288 - acc: 0.7988 - val_loss: 0.8239 - val_acc: 0.8477\n",
      "Epoch 35/50\n",
      "478424/478424 [==============================] - 103s 215us/sample - loss: 0.9247 - acc: 0.7994 - val_loss: 0.8242 - val_acc: 0.8465\n",
      "Epoch 36/50\n",
      "478424/478424 [==============================] - 103s 215us/sample - loss: 0.9214 - acc: 0.7998 - val_loss: 0.8234 - val_acc: 0.8476\n",
      "Epoch 37/50\n",
      "478424/478424 [==============================] - 103s 215us/sample - loss: 0.9213 - acc: 0.7998 - val_loss: 0.8208 - val_acc: 0.8477\n",
      "Epoch 38/50\n",
      "478424/478424 [==============================] - 103s 215us/sample - loss: 0.9161 - acc: 0.8003 - val_loss: 0.8183 - val_acc: 0.8478\n",
      "Epoch 39/50\n",
      "478424/478424 [==============================] - 103s 215us/sample - loss: 0.9125 - acc: 0.8019 - val_loss: 0.8151 - val_acc: 0.8487\n",
      "Epoch 40/50\n",
      "478424/478424 [==============================] - 103s 215us/sample - loss: 0.9121 - acc: 0.8010 - val_loss: 0.8139 - val_acc: 0.8484\n",
      "Epoch 41/50\n",
      "478424/478424 [==============================] - 103s 215us/sample - loss: 0.9075 - acc: 0.8023 - val_loss: 0.8095 - val_acc: 0.8491\n",
      "Epoch 42/50\n",
      "478424/478424 [==============================] - 103s 215us/sample - loss: 0.9059 - acc: 0.8030 - val_loss: 0.8087 - val_acc: 0.8493\n",
      "Epoch 43/50\n",
      "478424/478424 [==============================] - 103s 215us/sample - loss: 0.9015 - acc: 0.8029 - val_loss: 0.8123 - val_acc: 0.8488\n",
      "Epoch 44/50\n",
      "478424/478424 [==============================] - 103s 215us/sample - loss: 0.9007 - acc: 0.8029 - val_loss: 0.8115 - val_acc: 0.8484\n",
      "Epoch 45/50\n",
      "478424/478424 [==============================] - 103s 215us/sample - loss: 0.8841 - acc: 0.8056 - val_loss: 0.8031 - val_acc: 0.8502\n",
      "Epoch 46/50\n",
      "478424/478424 [==============================] - 103s 215us/sample - loss: 0.8830 - acc: 0.8067 - val_loss: 0.8027 - val_acc: 0.8508\n",
      "Epoch 47/50\n",
      "478424/478424 [==============================] - 103s 215us/sample - loss: 0.8815 - acc: 0.8060 - val_loss: 0.8016 - val_acc: 0.8503\n",
      "Epoch 48/50\n",
      "478424/478424 [==============================] - 103s 215us/sample - loss: 0.8774 - acc: 0.8076 - val_loss: 0.8016 - val_acc: 0.8505\n",
      "Epoch 49/50\n",
      "478424/478424 [==============================] - 103s 215us/sample - loss: 0.8797 - acc: 0.8072 - val_loss: 0.8007 - val_acc: 0.8508\n",
      "Epoch 50/50\n",
      "478424/478424 [==============================] - 103s 215us/sample - loss: 0.8787 - acc: 0.8070 - val_loss: 0.8012 - val_acc: 0.8506\n",
      "102520/102520 [==============================] - 9s 84us/sample - loss: 0.8007 - acc: 0.8508\n",
      "Test batchsize up\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0909 04:17:44.764260  3672 callbacks.py:875] `period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 478424 samples, validate on 102520 samples\n",
      "Epoch 1/50\n",
      "478424/478424 [==============================] - 50s 105us/sample - loss: 2.8150 - acc: 0.4984 - val_loss: 1.5730 - val_acc: 0.7050\n",
      "Epoch 2/50\n",
      "478424/478424 [==============================] - 49s 103us/sample - loss: 1.6918 - acc: 0.6648 - val_loss: 1.1959 - val_acc: 0.7719- ETA: 3s - loss: -\n",
      "Epoch 3/50\n",
      "478424/478424 [==============================] - 50s 104us/sample - loss: 1.3949 - acc: 0.7084 - val_loss: 1.0351 - val_acc: 0.8009 loss: 1.3987 - ac - ETA: 3s - loss: - ETA: 2s - l - ETA: 1s - loss: 1.3\n",
      "Epoch 4/50\n",
      "478424/478424 [==============================] - 50s 104us/sample - loss: 1.2334 - acc: 0.7319 - val_loss: 0.9385 - val_acc: 0.818531\n",
      "Epoch 5/50\n",
      "478424/478424 [==============================] - 50s 104us/sample - loss: 1.1255 - acc: 0.7490 - val_loss: 0.8745 - val_acc: 0.8298\n",
      "Epoch 6/50\n",
      "478424/478424 [==============================] - 50s 104us/sample - loss: 1.0512 - acc: 0.7604 - val_loss: 0.8344 - val_acc: 0.8385\n",
      "Epoch 7/50\n",
      "478424/478424 [==============================] - 50s 104us/sample - loss: 0.9887 - acc: 0.7706 - val_loss: 0.8014 - val_acc: 0.8439\n",
      "Epoch 8/50\n",
      "478424/478424 [==============================] - 50s 104us/sample - loss: 0.9412 - acc: 0.7787 - val_loss: 0.7565 - val_acc: 0.8516- - ETA: 6s - loss: 0.9415 - acc: 0. - ETA: 6s -\n",
      "Epoch 9/50\n",
      "478424/478424 [==============================] - 50s 104us/sample - loss: 0.9003 - acc: 0.7856 - val_loss: 0.7580 - val_acc: 0.8518\n",
      "Epoch 10/50\n",
      "478424/478424 [==============================] - 50s 104us/sample - loss: 0.8691 - acc: 0.7914 - val_loss: 0.7235 - val_acc: 0.8580\n",
      "Epoch 11/50\n",
      "478424/478424 [==============================] - 50s 104us/sample - loss: 0.8399 - acc: 0.7965 - val_loss: 0.7136 - val_acc: 0.8609\n",
      "Epoch 12/50\n",
      "478424/478424 [==============================] - 50s 104us/sample - loss: 0.8184 - acc: 0.8003 - val_loss: 0.6951 - val_acc: 0.8622\n",
      "Epoch 13/50\n",
      "478424/478424 [==============================] - 50s 104us/sample - loss: 0.7977 - acc: 0.8047 - val_loss: 0.7040 - val_acc: 0.8629 - l\n",
      "Epoch 14/50\n",
      "478424/478424 [==============================] - 50s 104us/sample - loss: 0.7795 - acc: 0.8080 - val_loss: 0.6906 - val_acc: 0.8652 - loss: 0.77\n",
      "Epoch 15/50\n",
      "478424/478424 [==============================] - 50s 104us/sample - loss: 0.7621 - acc: 0.8107 - val_loss: 0.6774 - val_acc: 0.8682ss: 0.7 - ETA: 0s - loss: 0.7617\n",
      "Epoch 16/50\n",
      "478424/478424 [==============================] - 50s 104us/sample - loss: 0.7484 - acc: 0.8136 - val_loss: 0.6756 - val_acc: 0.8694s: 0.7483 - acc: 0.81 - ETA: 0s - loss: 0.7485 \n",
      "Epoch 17/50\n",
      "478424/478424 [==============================] - 50s 104us/sample - loss: 0.7341 - acc: 0.8167 - val_loss: 0.6646 - val_acc: 0.8709\n",
      "Epoch 18/50\n",
      "478424/478424 [==============================] - 50s 104us/sample - loss: 0.7231 - acc: 0.8190 - val_loss: 0.6660 - val_acc: 0.8714\n",
      "Epoch 19/50\n",
      "478424/478424 [==============================] - 50s 104us/sample - loss: 0.7130 - acc: 0.8207 - val_loss: 0.6576 - val_acc: 0.8722\n",
      "Epoch 20/50\n",
      "478424/478424 [==============================] - 50s 104us/sample - loss: 0.7013 - acc: 0.8238 - val_loss: 0.6709 - val_acc: 0.8710\n",
      "Epoch 21/50\n",
      "478424/478424 [==============================] - 50s 104us/sample - loss: 0.6940 - acc: 0.8238 - val_loss: 0.6425 - val_acc: 0.8750\n",
      "Epoch 22/50\n",
      "478424/478424 [==============================] - 50s 104us/sample - loss: 0.6869 - acc: 0.8260 - val_loss: 0.6588 - val_acc: 0.8743\n",
      "Epoch 23/50\n",
      "478424/478424 [==============================] - 50s 104us/sample - loss: 0.6808 - acc: 0.8272 - val_loss: 0.6488 - val_acc: 0.8764\n",
      "Epoch 24/50\n",
      "478424/478424 [==============================] - 50s 104us/sample - loss: 0.6064 - acc: 0.8438 - val_loss: 0.6272 - val_acc: 0.8820\n",
      "Epoch 25/50\n",
      "478424/478424 [==============================] - 50s 104us/sample - loss: 0.5870 - acc: 0.8485 - val_loss: 0.6259 - val_acc: 0.8835\n",
      "Epoch 26/50\n",
      "478424/478424 [==============================] - 50s 104us/sample - loss: 0.5792 - acc: 0.8504 - val_loss: 0.6203 - val_acc: 0.8844\n",
      "Epoch 27/50\n",
      "478424/478424 [==============================] - 50s 104us/sample - loss: 0.5714 - acc: 0.8521 - val_loss: 0.6223 - val_acc: 0.88430.5717 - - ETA: 0s - loss: 0.5716 - \n",
      "Epoch 28/50\n",
      "478424/478424 [==============================] - 50s 104us/sample - loss: 0.5705 - acc: 0.8527 - val_loss: 0.6186 - val_acc: 0.8849\n",
      "Epoch 29/50\n",
      "478424/478424 [==============================] - 50s 104us/sample - loss: 0.5658 - acc: 0.8535 - val_loss: 0.6183 - val_acc: 0.8852\n",
      "Epoch 30/50\n",
      "478424/478424 [==============================] - 50s 104us/sample - loss: 0.5621 - acc: 0.8540 - val_loss: 0.6191 - val_acc: 0.8853\n",
      "Epoch 31/50\n",
      "478424/478424 [==============================] - 50s 104us/sample - loss: 0.5614 - acc: 0.8549 - val_loss: 0.6109 - val_acc: 0.8863loss: 0.5\n",
      "Epoch 32/50\n",
      "478424/478424 [==============================] - 50s 104us/sample - loss: 0.5570 - acc: 0.8553 - val_loss: 0.6108 - val_acc: 0.8856\n",
      "Epoch 33/50\n",
      "478424/478424 [==============================] - 50s 104us/sample - loss: 0.5554 - acc: 0.8556 - val_loss: 0.6163 - val_acc: 0.8863 - ETA: 3s - l\n",
      "Epoch 34/50\n",
      "478424/478424 [==============================] - 50s 104us/sample - loss: 0.5467 - acc: 0.8574 - val_loss: 0.6153 - val_acc: 0.8861\n",
      "Epoch 35/50\n",
      "478424/478424 [==============================] - 50s 104us/sample - loss: 0.5463 - acc: 0.8578 - val_loss: 0.6151 - val_acc: 0.8860\n",
      "Epoch 36/50\n",
      "478424/478424 [==============================] - 50s 104us/sample - loss: 0.5452 - acc: 0.8582 - val_loss: 0.6146 - val_acc: 0.8861\n",
      "Epoch 37/50\n",
      "478424/478424 [==============================] - 50s 104us/sample - loss: 0.5458 - acc: 0.8581 - val_loss: 0.6145 - val_acc: 0.8860\n",
      "102520/102520 [==============================] - 9s 88us/sample - loss: 0.6108 - acc: 0.8856\n",
      "New param set [5, 7, 4, 8]\n",
      "Test convolution down\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0909 04:48:36.283923  3672 callbacks.py:875] `period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 478424 samples, validate on 102520 samples\n",
      "Epoch 1/50\n",
      "478424/478424 [==============================] - 41s 85us/sample - loss: 3.1010 - acc: 0.4542 - val_loss: 1.7850 - val_acc: 0.6713\n",
      "Epoch 2/50\n",
      "478424/478424 [==============================] - 39s 82us/sample - loss: 1.9344 - acc: 0.6235 - val_loss: 1.4036 - val_acc: 0.7338\n",
      "Epoch 3/50\n",
      "478424/478424 [==============================] - 40s 83us/sample - loss: 1.6435 - acc: 0.6641 - val_loss: 1.2419 - val_acc: 0.7622\n",
      "Epoch 4/50\n",
      "478424/478424 [==============================] - 39s 82us/sample - loss: 1.4850 - acc: 0.6864 - val_loss: 1.1463 - val_acc: 0.7794\n",
      "Epoch 5/50\n",
      "478424/478424 [==============================] - 39s 82us/sample - loss: 1.3741 - acc: 0.7024 - val_loss: 1.0847 - val_acc: 0.7912\n",
      "Epoch 6/50\n",
      "478424/478424 [==============================] - 39s 82us/sample - loss: 1.2972 - acc: 0.7139 - val_loss: 1.0300 - val_acc: 0.7996\n",
      "Epoch 7/50\n",
      "478424/478424 [==============================] - 39s 82us/sample - loss: 1.2358 - acc: 0.7235 - val_loss: 0.9906 - val_acc: 0.8069\n",
      "Epoch 8/50\n",
      "478424/478424 [==============================] - 39s 82us/sample - loss: 1.1846 - acc: 0.7317 - val_loss: 0.9660 - val_acc: 0.8119\n",
      "Epoch 9/50\n",
      "478424/478424 [==============================] - 39s 82us/sample - loss: 1.1440 - acc: 0.7373 - val_loss: 0.9510 - val_acc: 0.8131\n",
      "Epoch 10/50\n",
      "478424/478424 [==============================] - 39s 82us/sample - loss: 1.1108 - acc: 0.7437 - val_loss: 0.9181 - val_acc: 0.8214\n",
      "Epoch 11/50\n",
      "478424/478424 [==============================] - 40s 83us/sample - loss: 1.0854 - acc: 0.7476 - val_loss: 0.9000 - val_acc: 0.8238\n",
      "Epoch 12/50\n",
      "478424/478424 [==============================] - 39s 82us/sample - loss: 1.0599 - acc: 0.7521 - val_loss: 0.9030 - val_acc: 0.8253\n",
      "Epoch 13/50\n",
      "478424/478424 [==============================] - 39s 82us/sample - loss: 1.0379 - acc: 0.7569 - val_loss: 0.8773 - val_acc: 0.8291\n",
      "Epoch 14/50\n",
      "478424/478424 [==============================] - 39s 82us/sample - loss: 1.0191 - acc: 0.7592 - val_loss: 0.8755 - val_acc: 0.8286\n",
      "Epoch 15/50\n",
      "478424/478424 [==============================] - 40s 83us/sample - loss: 1.0052 - acc: 0.7625 - val_loss: 0.8608 - val_acc: 0.8310\n",
      "Epoch 16/50\n",
      "478424/478424 [==============================] - 39s 82us/sample - loss: 0.9882 - acc: 0.7653 - val_loss: 0.8527 - val_acc: 0.8328\n",
      "Epoch 17/50\n",
      "478424/478424 [==============================] - 39s 82us/sample - loss: 0.9768 - acc: 0.7665 - val_loss: 0.8560 - val_acc: 0.8322\n",
      "Epoch 18/50\n",
      "478424/478424 [==============================] - 39s 82us/sample - loss: 0.9628 - acc: 0.7697 - val_loss: 0.8476 - val_acc: 0.8360\n",
      "Epoch 19/50\n",
      "478424/478424 [==============================] - 40s 83us/sample - loss: 0.9549 - acc: 0.7716 - val_loss: 0.8355 - val_acc: 0.8357\n",
      "Epoch 20/50\n",
      "478424/478424 [==============================] - 39s 82us/sample - loss: 0.9451 - acc: 0.7731 - val_loss: 0.8408 - val_acc: 0.8368\n",
      "Epoch 21/50\n",
      "478424/478424 [==============================] - 39s 82us/sample - loss: 0.9360 - acc: 0.7744 - val_loss: 0.8255 - val_acc: 0.8398\n",
      "Epoch 22/50\n",
      "478424/478424 [==============================] - 39s 82us/sample - loss: 0.9264 - acc: 0.7760 - val_loss: 0.8229 - val_acc: 0.8395\n",
      "Epoch 23/50\n",
      "478424/478424 [==============================] - 39s 83us/sample - loss: 0.9203 - acc: 0.7770 - val_loss: 0.8325 - val_acc: 0.8408\n",
      "Epoch 24/50\n",
      "478424/478424 [==============================] - 39s 82us/sample - loss: 0.9142 - acc: 0.7787 - val_loss: 0.8114 - val_acc: 0.8405\n",
      "Epoch 25/50\n",
      "478424/478424 [==============================] - 39s 82us/sample - loss: 0.9095 - acc: 0.7803 - val_loss: 0.8175 - val_acc: 0.8409\n",
      "Epoch 26/50\n",
      "478424/478424 [==============================] - 40s 83us/sample - loss: 0.9021 - acc: 0.7810 - val_loss: 0.8320 - val_acc: 0.8397\n",
      "Epoch 27/50\n",
      "478424/478424 [==============================] - 39s 82us/sample - loss: 0.8364 - acc: 0.7945 - val_loss: 0.8033 - val_acc: 0.8471\n",
      "Epoch 28/50\n",
      "478424/478424 [==============================] - 39s 82us/sample - loss: 0.8246 - acc: 0.7978 - val_loss: 0.7930 - val_acc: 0.8483\n",
      "Epoch 29/50\n",
      "478424/478424 [==============================] - 39s 82us/sample - loss: 0.8148 - acc: 0.8003 - val_loss: 0.7957 - val_acc: 0.8483\n",
      "Epoch 30/50\n",
      "478424/478424 [==============================] - 39s 82us/sample - loss: 0.8105 - acc: 0.8007 - val_loss: 0.7934 - val_acc: 0.8488\n",
      "Epoch 31/50\n",
      "478424/478424 [==============================] - 39s 82us/sample - loss: 0.8012 - acc: 0.8028 - val_loss: 0.7914 - val_acc: 0.8496\n",
      "Epoch 32/50\n",
      "478424/478424 [==============================] - 40s 83us/sample - loss: 0.8016 - acc: 0.8025 - val_loss: 0.7915 - val_acc: 0.8491\n",
      "Epoch 33/50\n",
      "478424/478424 [==============================] - 39s 82us/sample - loss: 0.8007 - acc: 0.8027 - val_loss: 0.7924 - val_acc: 0.8490\n",
      "Epoch 34/50\n",
      "478424/478424 [==============================] - 39s 82us/sample - loss: 0.8004 - acc: 0.8026 - val_loss: 0.7920 - val_acc: 0.8493\n",
      "Epoch 35/50\n",
      "478424/478424 [==============================] - 39s 82us/sample - loss: 0.8001 - acc: 0.8029 - val_loss: 0.7915 - val_acc: 0.8492\n",
      "Epoch 36/50\n",
      "478424/478424 [==============================] - 39s 82us/sample - loss: 0.8000 - acc: 0.8033 - val_loss: 0.7915 - val_acc: 0.8492\n",
      "102520/102520 [==============================] - 9s 87us/sample - loss: 0.7914 - acc: 0.8496\n",
      "Test convolution up\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0909 05:12:30.082556  3672 callbacks.py:875] `period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 478424 samples, validate on 102520 samples\n",
      "Epoch 1/50\n",
      "478424/478424 [==============================] - 74s 155us/sample - loss: 2.4850 - acc: 0.5553 - val_loss: 1.2730 - val_acc: 0.7605\n",
      "Epoch 2/50\n",
      "478424/478424 [==============================] - 73s 152us/sample - loss: 1.3633 - acc: 0.7246 - val_loss: 0.9215 - val_acc: 0.8232\n",
      "Epoch 3/50\n",
      "478424/478424 [==============================] - 72s 151us/sample - loss: 1.0834 - acc: 0.7662 - val_loss: 0.7864 - val_acc: 0.8455\n",
      "Epoch 4/50\n",
      "478424/478424 [==============================] - 72s 151us/sample - loss: 0.9383 - acc: 0.7884 - val_loss: 0.7116 - val_acc: 0.8610\n",
      "Epoch 5/50\n",
      "478424/478424 [==============================] - 73s 152us/sample - loss: 0.8397 - acc: 0.8044 - val_loss: 0.6624 - val_acc: 0.8704\n",
      "Epoch 6/50\n",
      "478424/478424 [==============================] - 73s 152us/sample - loss: 0.7693 - acc: 0.8164 - val_loss: 0.6341 - val_acc: 0.8742\n",
      "Epoch 7/50\n",
      "478424/478424 [==============================] - 72s 151us/sample - loss: 0.7131 - acc: 0.8265 - val_loss: 0.6078 - val_acc: 0.8809\n",
      "Epoch 8/50\n",
      "478424/478424 [==============================] - 72s 151us/sample - loss: 0.6677 - acc: 0.8345 - val_loss: 0.5854 - val_acc: 0.8855\n",
      "Epoch 9/50\n",
      "478424/478424 [==============================] - 73s 152us/sample - loss: 0.6318 - acc: 0.8412 - val_loss: 0.5718 - val_acc: 0.8876\n",
      "Epoch 10/50\n",
      "478424/478424 [==============================] - 73s 152us/sample - loss: 0.6033 - acc: 0.8468 - val_loss: 0.5612 - val_acc: 0.8910\n",
      "Epoch 11/50\n",
      "478424/478424 [==============================] - 72s 151us/sample - loss: 0.5806 - acc: 0.8518 - val_loss: 0.5513 - val_acc: 0.8932\n",
      "Epoch 12/50\n",
      "478424/478424 [==============================] - 72s 151us/sample - loss: 0.5579 - acc: 0.8561 - val_loss: 0.5481 - val_acc: 0.8940\n",
      "Epoch 13/50\n",
      "478424/478424 [==============================] - 72s 152us/sample - loss: 0.5412 - acc: 0.8591 - val_loss: 0.5411 - val_acc: 0.8963\n",
      "Epoch 14/50\n",
      "478424/478424 [==============================] - 72s 151us/sample - loss: 0.5236 - acc: 0.8635 - val_loss: 0.5484 - val_acc: 0.8967\n",
      "Epoch 15/50\n",
      "478424/478424 [==============================] - 73s 152us/sample - loss: 0.5135 - acc: 0.8650 - val_loss: 0.5438 - val_acc: 0.8962\n",
      "Epoch 16/50\n",
      "478424/478424 [==============================] - 72s 151us/sample - loss: 0.4293 - acc: 0.8848 - val_loss: 0.5234 - val_acc: 0.9036\n",
      "Epoch 17/50\n",
      "478424/478424 [==============================] - 72s 152us/sample - loss: 0.4089 - acc: 0.8901 - val_loss: 0.5207 - val_acc: 0.9050\n",
      "Epoch 18/50\n",
      "478424/478424 [==============================] - 73s 152us/sample - loss: 0.3974 - acc: 0.8931 - val_loss: 0.5140 - val_acc: 0.9063\n",
      "Epoch 19/50\n",
      "478424/478424 [==============================] - 72s 151us/sample - loss: 0.3913 - acc: 0.8940 - val_loss: 0.5147 - val_acc: 0.9068\n",
      "Epoch 20/50\n",
      "478424/478424 [==============================] - 72s 151us/sample - loss: 0.3828 - acc: 0.8958 - val_loss: 0.5153 - val_acc: 0.9071\n",
      "Epoch 21/50\n",
      "478424/478424 [==============================] - 72s 151us/sample - loss: 0.3749 - acc: 0.8978 - val_loss: 0.5155 - val_acc: 0.9073\n",
      "Epoch 22/50\n",
      "478424/478424 [==============================] - 72s 152us/sample - loss: 0.3724 - acc: 0.8985 - val_loss: 0.5153 - val_acc: 0.9073\n",
      "Epoch 23/50\n",
      "478424/478424 [==============================] - 72s 151us/sample - loss: 0.3719 - acc: 0.8986 - val_loss: 0.5155 - val_acc: 0.9072\n",
      "102520/102520 [==============================] - 11s 103us/sample - loss: 0.5140 - acc: 0.9063\n",
      "New param set [5, 7, 5, 8]\n",
      "Test dense down\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0909 05:40:33.297085  3672 callbacks.py:875] `period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 478424 samples, validate on 102520 samples\n",
      "Epoch 1/50\n",
      "478424/478424 [==============================] - 72s 150us/sample - loss: 2.7828 - acc: 0.4969 - val_loss: 1.4859 - val_acc: 0.7185\n",
      "Epoch 2/50\n",
      "478424/478424 [==============================] - 70s 146us/sample - loss: 1.6770 - acc: 0.6596 - val_loss: 1.0991 - val_acc: 0.7850\n",
      "Epoch 3/50\n",
      "478424/478424 [==============================] - 70s 146us/sample - loss: 1.3963 - acc: 0.7027 - val_loss: 0.9341 - val_acc: 0.8158\n",
      "Epoch 4/50\n",
      "478424/478424 [==============================] - 70s 146us/sample - loss: 1.2468 - acc: 0.7263 - val_loss: 0.8486 - val_acc: 0.8320\n",
      "Epoch 5/50\n",
      "478424/478424 [==============================] - 70s 146us/sample - loss: 1.1472 - acc: 0.7436 - val_loss: 0.7937 - val_acc: 0.8427\n",
      "Epoch 6/50\n",
      "478424/478424 [==============================] - 70s 146us/sample - loss: 1.0693 - acc: 0.7558 - val_loss: 0.7429 - val_acc: 0.8519\n",
      "Epoch 7/50\n",
      "478424/478424 [==============================] - 70s 146us/sample - loss: 1.0134 - acc: 0.7657 - val_loss: 0.7164 - val_acc: 0.8582\n",
      "Epoch 8/50\n",
      "478424/478424 [==============================] - 70s 146us/sample - loss: 0.9701 - acc: 0.7730 - val_loss: 0.6853 - val_acc: 0.8627\n",
      "Epoch 9/50\n",
      "478424/478424 [==============================] - 70s 146us/sample - loss: 0.9333 - acc: 0.7798 - val_loss: 0.6714 - val_acc: 0.8652\n",
      "Epoch 10/50\n",
      "478424/478424 [==============================] - 70s 146us/sample - loss: 0.9019 - acc: 0.7847 - val_loss: 0.6482 - val_acc: 0.8705\n",
      "Epoch 11/50\n",
      "478424/478424 [==============================] - 70s 146us/sample - loss: 0.8737 - acc: 0.7904 - val_loss: 0.6370 - val_acc: 0.8721\n",
      "Epoch 12/50\n",
      "478424/478424 [==============================] - 70s 146us/sample - loss: 0.8519 - acc: 0.7941 - val_loss: 0.6262 - val_acc: 0.8756\n",
      "Epoch 13/50\n",
      "478424/478424 [==============================] - 70s 146us/sample - loss: 0.8365 - acc: 0.7978 - val_loss: 0.6142 - val_acc: 0.8768\n",
      "Epoch 14/50\n",
      "478424/478424 [==============================] - 70s 146us/sample - loss: 0.8192 - acc: 0.8004 - val_loss: 0.6090 - val_acc: 0.8781\n",
      "Epoch 15/50\n",
      "478424/478424 [==============================] - 70s 146us/sample - loss: 0.8069 - acc: 0.8026 - val_loss: 0.6064 - val_acc: 0.8788\n",
      "Epoch 16/50\n",
      "478424/478424 [==============================] - 70s 146us/sample - loss: 0.7957 - acc: 0.8045 - val_loss: 0.5988 - val_acc: 0.8793\n",
      "Epoch 17/50\n",
      "478424/478424 [==============================] - 70s 146us/sample - loss: 0.7896 - acc: 0.8060 - val_loss: 0.5887 - val_acc: 0.8823\n",
      "Epoch 18/50\n",
      "478424/478424 [==============================] - 70s 146us/sample - loss: 0.7783 - acc: 0.8079 - val_loss: 0.5853 - val_acc: 0.8822\n",
      "Epoch 19/50\n",
      "478424/478424 [==============================] - 70s 146us/sample - loss: 0.7699 - acc: 0.8092 - val_loss: 0.5830 - val_acc: 0.8834\n",
      "Epoch 20/50\n",
      "478424/478424 [==============================] - 70s 146us/sample - loss: 0.7608 - acc: 0.8117 - val_loss: 0.5818 - val_acc: 0.8838\n",
      "Epoch 21/50\n",
      "478424/478424 [==============================] - 70s 146us/sample - loss: 0.7577 - acc: 0.8118 - val_loss: 0.5776 - val_acc: 0.8845\n",
      "Epoch 22/50\n",
      "478424/478424 [==============================] - 70s 146us/sample - loss: 0.7493 - acc: 0.8137 - val_loss: 0.5735 - val_acc: 0.8849\n",
      "Epoch 23/50\n",
      "478424/478424 [==============================] - 70s 146us/sample - loss: 0.7418 - acc: 0.8153 - val_loss: 0.5750 - val_acc: 0.8854\n",
      "Epoch 24/50\n",
      "478424/478424 [==============================] - 70s 146us/sample - loss: 0.7380 - acc: 0.8156 - val_loss: 0.5632 - val_acc: 0.8875\n",
      "Epoch 25/50\n",
      "478424/478424 [==============================] - 70s 146us/sample - loss: 0.7309 - acc: 0.8175 - val_loss: 0.5728 - val_acc: 0.8858\n",
      "Epoch 26/50\n",
      "478424/478424 [==============================] - 70s 146us/sample - loss: 0.7271 - acc: 0.8184 - val_loss: 0.5624 - val_acc: 0.8879\n",
      "Epoch 27/50\n",
      "478424/478424 [==============================] - 70s 146us/sample - loss: 0.7218 - acc: 0.8190 - val_loss: 0.5570 - val_acc: 0.8886\n",
      "Epoch 28/50\n",
      "478424/478424 [==============================] - 70s 146us/sample - loss: 0.7167 - acc: 0.8200 - val_loss: 0.5647 - val_acc: 0.8881\n",
      "Epoch 29/50\n",
      "478424/478424 [==============================] - 70s 147us/sample - loss: 0.7129 - acc: 0.8216 - val_loss: 0.5668 - val_acc: 0.8883\n",
      "Epoch 30/50\n",
      "478424/478424 [==============================] - 70s 146us/sample - loss: 0.6344 - acc: 0.8378 - val_loss: 0.5391 - val_acc: 0.8944\n",
      "Epoch 31/50\n",
      "478424/478424 [==============================] - 70s 146us/sample - loss: 0.6167 - acc: 0.8426 - val_loss: 0.5330 - val_acc: 0.8954\n",
      "Epoch 32/50\n",
      "478424/478424 [==============================] - 70s 146us/sample - loss: 0.6065 - acc: 0.8449 - val_loss: 0.5293 - val_acc: 0.8961\n",
      "Epoch 33/50\n",
      "478424/478424 [==============================] - 70s 146us/sample - loss: 0.6003 - acc: 0.8464 - val_loss: 0.5299 - val_acc: 0.8964\n",
      "Epoch 34/50\n",
      "478424/478424 [==============================] - 70s 146us/sample - loss: 0.5929 - acc: 0.8474 - val_loss: 0.5246 - val_acc: 0.8969\n",
      "Epoch 35/50\n",
      "478424/478424 [==============================] - 70s 146us/sample - loss: 0.5877 - acc: 0.8488 - val_loss: 0.5281 - val_acc: 0.8971\n",
      "Epoch 36/50\n",
      "478424/478424 [==============================] - 70s 146us/sample - loss: 0.5821 - acc: 0.8502 - val_loss: 0.5264 - val_acc: 0.8974\n",
      "Epoch 37/50\n",
      "478424/478424 [==============================] - 70s 146us/sample - loss: 0.5774 - acc: 0.8510 - val_loss: 0.5244 - val_acc: 0.8976\n",
      "Epoch 38/50\n",
      "478424/478424 [==============================] - 70s 146us/sample - loss: 0.5734 - acc: 0.8517 - val_loss: 0.5244 - val_acc: 0.8980\n",
      "Epoch 39/50\n",
      "478424/478424 [==============================] - 70s 146us/sample - loss: 0.5741 - acc: 0.8514 - val_loss: 0.5244 - val_acc: 0.8977\n",
      "Epoch 40/50\n",
      "478424/478424 [==============================] - 70s 146us/sample - loss: 0.5738 - acc: 0.8514 - val_loss: 0.5240 - val_acc: 0.8978\n",
      "Epoch 41/50\n",
      "478424/478424 [==============================] - 70s 146us/sample - loss: 0.5731 - acc: 0.8525 - val_loss: 0.5238 - val_acc: 0.8978\n",
      "Epoch 42/50\n",
      "478424/478424 [==============================] - 70s 146us/sample - loss: 0.5725 - acc: 0.8530 - val_loss: 0.5237 - val_acc: 0.8979\n",
      "Epoch 43/50\n",
      "478424/478424 [==============================] - 70s 146us/sample - loss: 0.5717 - acc: 0.8522 - val_loss: 0.5238 - val_acc: 0.8980\n",
      "Epoch 44/50\n",
      "478424/478424 [==============================] - 70s 146us/sample - loss: 0.5708 - acc: 0.8522 - val_loss: 0.5238 - val_acc: 0.8979\n",
      "Epoch 45/50\n",
      "478424/478424 [==============================] - 70s 146us/sample - loss: 0.5736 - acc: 0.8516 - val_loss: 0.5238 - val_acc: 0.8980\n",
      "Epoch 46/50\n",
      "478424/478424 [==============================] - 70s 146us/sample - loss: 0.5720 - acc: 0.8522 - val_loss: 0.5238 - val_acc: 0.8979\n",
      "Epoch 47/50\n",
      "478424/478424 [==============================] - 70s 146us/sample - loss: 0.5720 - acc: 0.8524 - val_loss: 0.5238 - val_acc: 0.8979\n",
      "102520/102520 [==============================] - 11s 110us/sample - loss: 0.5237 - acc: 0.8979\n",
      "Test dense up\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0909 06:35:35.613968  3672 callbacks.py:875] `period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 478424 samples, validate on 102520 samples\n",
      "Epoch 1/50\n",
      "478424/478424 [==============================] - 81s 168us/sample - loss: 2.2931 - acc: 0.5930 - val_loss: 1.1742 - val_acc: 0.7839\n",
      "Epoch 2/50\n",
      "478424/478424 [==============================] - 79s 164us/sample - loss: 1.1955 - acc: 0.7600 - val_loss: 0.8402 - val_acc: 0.8410\n",
      "Epoch 3/50\n",
      "478424/478424 [==============================] - 79s 165us/sample - loss: 0.9101 - acc: 0.8026 - val_loss: 0.7104 - val_acc: 0.8639\n",
      "Epoch 4/50\n",
      "478424/478424 [==============================] - 79s 165us/sample - loss: 0.7569 - acc: 0.8269 - val_loss: 0.6407 - val_acc: 0.8765\n",
      "Epoch 5/50\n",
      "478424/478424 [==============================] - 79s 165us/sample - loss: 0.6559 - acc: 0.8435 - val_loss: 0.6072 - val_acc: 0.8831\n",
      "Epoch 6/50\n",
      "478424/478424 [==============================] - 79s 164us/sample - loss: 0.5811 - acc: 0.8556 - val_loss: 0.5716 - val_acc: 0.8902\n",
      "Epoch 7/50\n",
      "478424/478424 [==============================] - 79s 164us/sample - loss: 0.5242 - acc: 0.8664 - val_loss: 0.5523 - val_acc: 0.8936\n",
      "Epoch 8/50\n",
      "478424/478424 [==============================] - 79s 164us/sample - loss: 0.4813 - acc: 0.8745 - val_loss: 0.5420 - val_acc: 0.8963\n",
      "Epoch 9/50\n",
      "478424/478424 [==============================] - 78s 164us/sample - loss: 0.4427 - acc: 0.8829 - val_loss: 0.5238 - val_acc: 0.8998\n",
      "Epoch 10/50\n",
      "478424/478424 [==============================] - 78s 164us/sample - loss: 0.4160 - acc: 0.8875 - val_loss: 0.5284 - val_acc: 0.9014\n",
      "Epoch 11/50\n",
      "478424/478424 [==============================] - 79s 164us/sample - loss: 0.3943 - acc: 0.8927 - val_loss: 0.5208 - val_acc: 0.9032\n",
      "Epoch 12/50\n",
      "478424/478424 [==============================] - 79s 164us/sample - loss: 0.3767 - acc: 0.8963 - val_loss: 0.5188 - val_acc: 0.90430.\n",
      "Epoch 13/50\n",
      "478424/478424 [==============================] - 79s 164us/sample - loss: 0.3576 - acc: 0.9019 - val_loss: 0.5084 - val_acc: 0.9057\n",
      "Epoch 14/50\n",
      "478424/478424 [==============================] - 78s 164us/sample - loss: 0.3460 - acc: 0.9033 - val_loss: 0.5120 - val_acc: 0.9062\n",
      "Epoch 15/50\n",
      "478424/478424 [==============================] - 79s 165us/sample - loss: 0.3367 - acc: 0.9055 - val_loss: 0.5306 - val_acc: 0.9063\n",
      "Epoch 16/50\n",
      "478424/478424 [==============================] - 79s 164us/sample - loss: 0.2570 - acc: 0.9261 - val_loss: 0.5176 - val_acc: 0.9128\n",
      "Epoch 17/50\n",
      "478424/478424 [==============================] - 79s 164us/sample - loss: 0.2368 - acc: 0.9311 - val_loss: 0.5187 - val_acc: 0.9135\n",
      "Epoch 18/50\n",
      "478424/478424 [==============================] - 79s 164us/sample - loss: 0.2272 - acc: 0.9338 - val_loss: 0.5184 - val_acc: 0.9141\n",
      "102520/102520 [==============================] - 12s 113us/sample - loss: 0.5084 - acc: 0.9057\n",
      "New param set [5, 7, 5, 9]\n",
      "Test dropout down\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0909 06:59:29.887637  3672 callbacks.py:875] `period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 478424 samples, validate on 102520 samples\n",
      "Epoch 1/50\n",
      "478424/478424 [==============================] - 81s 170us/sample - loss: 2.1841 - acc: 0.6122 - val_loss: 1.0895 - val_acc: 0.7976\n",
      "Epoch 2/50\n",
      "478424/478424 [==============================] - 79s 165us/sample - loss: 1.0560 - acc: 0.7830 - val_loss: 0.7665 - val_acc: 0.8532\n",
      "Epoch 3/50\n",
      "478424/478424 [==============================] - 79s 165us/sample - loss: 0.7810 - acc: 0.8250 - val_loss: 0.6523 - val_acc: 0.8729\n",
      "Epoch 4/50\n",
      "478424/478424 [==============================] - 79s 165us/sample - loss: 0.6337 - acc: 0.8492 - val_loss: 0.5954 - val_acc: 0.8846\n",
      "Epoch 5/50\n",
      "478424/478424 [==============================] - 79s 165us/sample - loss: 0.5416 - acc: 0.8654 - val_loss: 0.5778 - val_acc: 0.8895\n",
      "Epoch 6/50\n",
      "478424/478424 [==============================] - 79s 165us/sample - loss: 0.4733 - acc: 0.8773 - val_loss: 0.5417 - val_acc: 0.8957\n",
      "Epoch 7/50\n",
      "478424/478424 [==============================] - 79s 165us/sample - loss: 0.4229 - acc: 0.8883 - val_loss: 0.5540 - val_acc: 0.8976\n",
      "Epoch 8/50\n",
      "478424/478424 [==============================] - 79s 165us/sample - loss: 0.3829 - acc: 0.8962 - val_loss: 0.5368 - val_acc: 0.8996\n",
      "Epoch 9/50\n",
      "478424/478424 [==============================] - 79s 165us/sample - loss: 0.3528 - acc: 0.9026 - val_loss: 0.5212 - val_acc: 0.9026\n",
      "Epoch 10/50\n",
      "478424/478424 [==============================] - 79s 164us/sample - loss: 0.3289 - acc: 0.9084 - val_loss: 0.5265 - val_acc: 0.9039\n",
      "Epoch 11/50\n",
      "478424/478424 [==============================] - 79s 165us/sample - loss: 0.3084 - acc: 0.9131 - val_loss: 0.5375 - val_acc: 0.9043\n",
      "Epoch 12/50\n",
      "478424/478424 [==============================] - 79s 164us/sample - loss: 0.2246 - acc: 0.9346 - val_loss: 0.5370 - val_acc: 0.9112\n",
      "Epoch 13/50\n",
      "478424/478424 [==============================] - 79s 165us/sample - loss: 0.2052 - acc: 0.9402 - val_loss: 0.5363 - val_acc: 0.9131\n",
      "Epoch 14/50\n",
      "478424/478424 [==============================] - 79s 165us/sample - loss: 0.1925 - acc: 0.9430 - val_loss: 0.5373 - val_acc: 0.9131\n",
      "102520/102520 [==============================] - 12s 119us/sample - loss: 0.5212 - acc: 0.9026\n",
      "Test dropout up\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0909 07:18:13.464727  3672 callbacks.py:875] `period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 478424 samples, validate on 102520 samples\n",
      "Epoch 1/50\n",
      "478424/478424 [==============================] - 82s 171us/sample - loss: 2.4482 - acc: 0.5659 - val_loss: 1.2800 - val_acc: 0.7643\n",
      "Epoch 2/50\n",
      "478424/478424 [==============================] - 80s 166us/sample - loss: 1.3545 - acc: 0.7313 - val_loss: 0.9273 - val_acc: 0.8245\n",
      "Epoch 3/50\n",
      "478424/478424 [==============================] - 79s 166us/sample - loss: 1.0627 - acc: 0.7750 - val_loss: 0.7898 - val_acc: 0.8497\n",
      "Epoch 4/50\n",
      "478424/478424 [==============================] - 79s 166us/sample - loss: 0.9041 - acc: 0.7993 - val_loss: 0.7062 - val_acc: 0.8636\n",
      "Epoch 5/50\n",
      "478424/478424 [==============================] - 79s 166us/sample - loss: 0.8009 - acc: 0.8155 - val_loss: 0.6458 - val_acc: 0.8745\n",
      "Epoch 6/50\n",
      "478424/478424 [==============================] - 79s 166us/sample - loss: 0.7250 - acc: 0.8276 - val_loss: 0.6284 - val_acc: 0.8780\n",
      "Epoch 7/50\n",
      "478424/478424 [==============================] - 79s 166us/sample - loss: 0.6625 - acc: 0.8386 - val_loss: 0.5987 - val_acc: 0.8836\n",
      "Epoch 8/50\n",
      "478424/478424 [==============================] - 79s 166us/sample - loss: 0.6144 - acc: 0.8469 - val_loss: 0.5780 - val_acc: 0.8871\n",
      "Epoch 9/50\n",
      "478424/478424 [==============================] - 79s 166us/sample - loss: 0.5776 - acc: 0.8537 - val_loss: 0.5649 - val_acc: 0.8905\n",
      "Epoch 10/50\n",
      "478424/478424 [==============================] - 79s 166us/sample - loss: 0.5454 - acc: 0.8598 - val_loss: 0.5437 - val_acc: 0.8937\n",
      "Epoch 11/50\n",
      "478424/478424 [==============================] - 79s 166us/sample - loss: 0.5190 - acc: 0.8652 - val_loss: 0.5525 - val_acc: 0.8953\n",
      "Epoch 12/50\n",
      "478424/478424 [==============================] - 79s 166us/sample - loss: 0.4978 - acc: 0.8691 - val_loss: 0.5346 - val_acc: 0.8975\n",
      "Epoch 13/50\n",
      "478424/478424 [==============================] - 79s 166us/sample - loss: 0.4806 - acc: 0.8732 - val_loss: 0.5578 - val_acc: 0.8985\n",
      "Epoch 14/50\n",
      "478424/478424 [==============================] - 80s 167us/sample - loss: 0.4672 - acc: 0.8756 - val_loss: 0.5368 - val_acc: 0.8974\n",
      "Epoch 15/50\n",
      "478424/478424 [==============================] - 79s 166us/sample - loss: 0.3782 - acc: 0.8964 - val_loss: 0.5267 - val_acc: 0.9052\n",
      "Epoch 16/50\n",
      "478424/478424 [==============================] - 79s 166us/sample - loss: 0.3547 - acc: 0.9025 - val_loss: 0.5218 - val_acc: 0.9063\n",
      "Epoch 17/50\n",
      "478424/478424 [==============================] - 79s 166us/sample - loss: 0.3432 - acc: 0.9055 - val_loss: 0.5249 - val_acc: 0.9076\n",
      "Epoch 18/50\n",
      "478424/478424 [==============================] - 79s 166us/sample - loss: 0.3342 - acc: 0.9075 - val_loss: 0.5212 - val_acc: 0.9083\n",
      "Epoch 19/50\n",
      "478424/478424 [==============================] - 79s 166us/sample - loss: 0.3264 - acc: 0.9094 - val_loss: 0.5214 - val_acc: 0.9086\n",
      "Epoch 20/50\n",
      "478424/478424 [==============================] - 79s 166us/sample - loss: 0.3205 - acc: 0.9107 - val_loss: 0.5224 - val_acc: 0.9084\n",
      "Epoch 21/50\n",
      "478424/478424 [==============================] - 79s 166us/sample - loss: 0.3115 - acc: 0.9128 - val_loss: 0.5199 - val_acc: 0.9091\n",
      "Epoch 22/50\n",
      "478424/478424 [==============================] - 79s 166us/sample - loss: 0.3095 - acc: 0.9135 - val_loss: 0.5183 - val_acc: 0.9095\n",
      "Epoch 23/50\n",
      "478424/478424 [==============================] - 79s 165us/sample - loss: 0.3074 - acc: 0.9140 - val_loss: 0.5191 - val_acc: 0.9095\n",
      "Epoch 24/50\n",
      "478424/478424 [==============================] - 79s 166us/sample - loss: 0.3078 - acc: 0.9141 - val_loss: 0.5195 - val_acc: 0.9097:  - ETA: 2s - loss: 0. - ETA: 1s - loss\n",
      "Epoch 25/50\n",
      "478424/478424 [==============================] - 79s 165us/sample - loss: 0.3076 - acc: 0.9143 - val_loss: 0.5194 - val_acc: 0.9096\n",
      "Epoch 26/50\n",
      "478424/478424 [==============================] - 79s 166us/sample - loss: 0.3081 - acc: 0.9136 - val_loss: 0.5189 - val_acc: 0.9097\n",
      "Epoch 27/50\n",
      "478424/478424 [==============================] - 79s 166us/sample - loss: 0.3079 - acc: 0.9137 - val_loss: 0.5189 - val_acc: 0.9097\n",
      "102520/102520 [==============================] - 12s 121us/sample - loss: 0.5183 - acc: 0.9095\n",
      "Test batchsize down\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0909 07:54:16.258901  3672 callbacks.py:875] `period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 478424 samples, validate on 102520 samples\n",
      "Epoch 1/50\n",
      "478424/478424 [==============================] - 106s 222us/sample - loss: 2.2473 - acc: 0.6067 - val_loss: 1.2177 - val_acc: 0.7845\n",
      "Epoch 2/50\n",
      "478424/478424 [==============================] - 103s 215us/sample - loss: 1.2745 - acc: 0.7523 - val_loss: 0.9300 - val_acc: 0.8313\n",
      "Epoch 3/50\n",
      "478424/478424 [==============================] - 103s 216us/sample - loss: 1.0206 - acc: 0.7883 - val_loss: 0.7954 - val_acc: 0.8518\n",
      "Epoch 4/50\n",
      "478424/478424 [==============================] - 103s 216us/sample - loss: 0.8796 - acc: 0.8095 - val_loss: 0.7132 - val_acc: 0.8660\n",
      "Epoch 5/50\n",
      "478424/478424 [==============================] - 103s 216us/sample - loss: 0.7804 - acc: 0.8255 - val_loss: 0.6712 - val_acc: 0.8732\n",
      "Epoch 6/50\n",
      "478424/478424 [==============================] - 103s 216us/sample - loss: 0.7077 - acc: 0.8369 - val_loss: 0.6320 - val_acc: 0.8794\n",
      "Epoch 7/50\n",
      "478424/478424 [==============================] - 103s 216us/sample - loss: 0.6499 - acc: 0.8460 - val_loss: 0.6102 - val_acc: 0.8842\n",
      "Epoch 8/50\n",
      "478424/478424 [==============================] - 103s 216us/sample - loss: 0.6035 - acc: 0.8538 - val_loss: 0.5871 - val_acc: 0.8862\n",
      "Epoch 9/50\n",
      "478424/478424 [==============================] - 104s 216us/sample - loss: 0.5692 - acc: 0.8597 - val_loss: 0.5675 - val_acc: 0.8901\n",
      "Epoch 10/50\n",
      "478424/478424 [==============================] - 103s 216us/sample - loss: 0.5399 - acc: 0.8647 - val_loss: 0.5706 - val_acc: 0.8918\n",
      "Epoch 11/50\n",
      "478424/478424 [==============================] - 103s 216us/sample - loss: 0.5194 - acc: 0.8692 - val_loss: 0.5517 - val_acc: 0.8942\n",
      "Epoch 12/50\n",
      "478424/478424 [==============================] - 103s 216us/sample - loss: 0.5018 - acc: 0.8716 - val_loss: 0.5766 - val_acc: 0.8939\n",
      "Epoch 13/50\n",
      "478424/478424 [==============================] - 104s 217us/sample - loss: 0.4848 - acc: 0.8750 - val_loss: 0.5546 - val_acc: 0.8951\n",
      "Epoch 14/50\n",
      "478424/478424 [==============================] - 104s 216us/sample - loss: 0.3718 - acc: 0.9001 - val_loss: 0.5450 - val_acc: 0.9027\n",
      "Epoch 15/50\n",
      "478424/478424 [==============================] - 104s 216us/sample - loss: 0.3435 - acc: 0.9070 - val_loss: 0.5444 - val_acc: 0.9037\n",
      "Epoch 16/50\n",
      "478424/478424 [==============================] - 104s 217us/sample - loss: 0.3299 - acc: 0.9103 - val_loss: 0.5365 - val_acc: 0.9049\n",
      "Epoch 17/50\n",
      "478424/478424 [==============================] - 104s 217us/sample - loss: 0.3201 - acc: 0.9128 - val_loss: 0.5328 - val_acc: 0.9056\n",
      "Epoch 18/50\n",
      "478424/478424 [==============================] - 104s 217us/sample - loss: 0.3098 - acc: 0.9150 - val_loss: 0.5311 - val_acc: 0.9064\n",
      "Epoch 19/50\n",
      "478424/478424 [==============================] - 104s 217us/sample - loss: 0.3022 - acc: 0.9168 - val_loss: 0.5267 - val_acc: 0.9066\n",
      "Epoch 20/50\n",
      "478424/478424 [==============================] - 104s 217us/sample - loss: 0.2968 - acc: 0.9182 - val_loss: 0.5327 - val_acc: 0.9069\n",
      "Epoch 21/50\n",
      "478424/478424 [==============================] - 104s 217us/sample - loss: 0.2920 - acc: 0.9193 - val_loss: 0.5286 - val_acc: 0.9069\n",
      "Epoch 22/50\n",
      "478424/478424 [==============================] - 104s 216us/sample - loss: 0.2796 - acc: 0.9223 - val_loss: 0.5315 - val_acc: 0.9073\n",
      "Epoch 23/50\n",
      "478424/478424 [==============================] - 104s 217us/sample - loss: 0.2792 - acc: 0.9227 - val_loss: 0.5300 - val_acc: 0.9078\n",
      "Epoch 24/50\n",
      "478424/478424 [==============================] - 104s 217us/sample - loss: 0.2759 - acc: 0.9229 - val_loss: 0.5299 - val_acc: 0.9078\n",
      "102520/102520 [==============================] - 13s 123us/sample - loss: 0.5267 - acc: 0.9066\n",
      "Test batchsize up\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0909 08:36:03.553085  3672 callbacks.py:875] `period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 478424 samples, validate on 102520 samples\n",
      "Epoch 1/50\n",
      "478424/478424 [==============================] - 70s 147us/sample - loss: 2.4559 - acc: 0.5606 - val_loss: 1.2130 - val_acc: 0.7712\n",
      "Epoch 2/50\n",
      "478424/478424 [==============================] - 67s 140us/sample - loss: 1.2063 - acc: 0.7521 - val_loss: 0.8355 - val_acc: 0.8355\n",
      "Epoch 3/50\n",
      "478424/478424 [==============================] - 67s 140us/sample - loss: 0.8940 - acc: 0.8013 - val_loss: 0.6903 - val_acc: 0.8614\n",
      "Epoch 4/50\n",
      "478424/478424 [==============================] - 67s 140us/sample - loss: 0.7247 - acc: 0.8286 - val_loss: 0.6319 - val_acc: 0.8739\n",
      "Epoch 5/50\n",
      "478424/478424 [==============================] - 67s 140us/sample - loss: 0.6191 - acc: 0.8478 - val_loss: 0.5911 - val_acc: 0.8821\n",
      "Epoch 6/50\n",
      "478424/478424 [==============================] - 67s 140us/sample - loss: 0.5482 - acc: 0.8605 - val_loss: 0.5642 - val_acc: 0.8900\n",
      "Epoch 7/50\n",
      "478424/478424 [==============================] - 67s 140us/sample - loss: 0.4934 - acc: 0.8709 - val_loss: 0.5467 - val_acc: 0.8939\n",
      "Epoch 8/50\n",
      "478424/478424 [==============================] - 67s 140us/sample - loss: 0.4516 - acc: 0.8801 - val_loss: 0.5434 - val_acc: 0.8959\n",
      "Epoch 9/50\n",
      "478424/478424 [==============================] - 67s 140us/sample - loss: 0.4180 - acc: 0.8871 - val_loss: 0.5384 - val_acc: 0.8984\n",
      "Epoch 10/50\n",
      "478424/478424 [==============================] - 67s 140us/sample - loss: 0.3903 - acc: 0.8928 - val_loss: 0.5470 - val_acc: 0.8993\n",
      "Epoch 11/50\n",
      "478424/478424 [==============================] - 67s 140us/sample - loss: 0.3682 - acc: 0.8978 - val_loss: 0.5341 - val_acc: 0.9015\n",
      "Epoch 12/50\n",
      "478424/478424 [==============================] - 67s 140us/sample - loss: 0.3487 - acc: 0.9024 - val_loss: 0.5342 - val_acc: 0.9030\n",
      "Epoch 13/50\n",
      "478424/478424 [==============================] - 68s 141us/sample - loss: 0.3323 - acc: 0.9064 - val_loss: 0.5374 - val_acc: 0.9045\n",
      "Epoch 14/50\n",
      "478424/478424 [==============================] - 67s 140us/sample - loss: 0.2607 - acc: 0.9246 - val_loss: 0.5296 - val_acc: 0.9104\n",
      "Epoch 15/50\n",
      "478424/478424 [==============================] - 67s 141us/sample - loss: 0.2424 - acc: 0.9295 - val_loss: 0.5267 - val_acc: 0.9117\n",
      "Epoch 16/50\n",
      "478424/478424 [==============================] - 67s 141us/sample - loss: 0.2329 - acc: 0.9324 - val_loss: 0.5305 - val_acc: 0.9121\n",
      "Epoch 17/50\n",
      "478424/478424 [==============================] - 67s 141us/sample - loss: 0.2272 - acc: 0.9336 - val_loss: 0.5316 - val_acc: 0.9128\n",
      "Epoch 18/50\n",
      "478424/478424 [==============================] - 67s 141us/sample - loss: 0.2184 - acc: 0.9359 - val_loss: 0.5345 - val_acc: 0.9128\n",
      "Epoch 19/50\n",
      "478424/478424 [==============================] - 67s 141us/sample - loss: 0.2171 - acc: 0.9365 - val_loss: 0.5355 - val_acc: 0.9129\n",
      "Epoch 20/50\n",
      "478424/478424 [==============================] - 67s 141us/sample - loss: 0.2147 - acc: 0.9369 - val_loss: 0.5358 - val_acc: 0.9129\n",
      "102520/102520 [==============================] - 14s 137us/sample - loss: 0.5267 - acc: 0.9117 - loss: 0.5268 - acc: 0.91\n",
      "Test convolution down\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0909 08:58:51.397223  3672 callbacks.py:875] `period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 478424 samples, validate on 102520 samples\n",
      "Epoch 1/50\n",
      "478424/478424 [==============================] - 61s 128us/sample - loss: 2.5745 - acc: 0.5455 - val_loss: 1.4346 - val_acc: 0.7366\n",
      "Epoch 2/50\n",
      "478424/478424 [==============================] - 58s 121us/sample - loss: 1.4535 - acc: 0.7123 - val_loss: 1.0685 - val_acc: 0.7988\n",
      "Epoch 3/50\n",
      "478424/478424 [==============================] - 58s 121us/sample - loss: 1.1513 - acc: 0.7575 - val_loss: 0.9205 - val_acc: 0.8243\n",
      "Epoch 4/50\n",
      "478424/478424 [==============================] - 58s 121us/sample - loss: 0.9820 - acc: 0.7827 - val_loss: 0.8206 - val_acc: 0.8426\n",
      "Epoch 5/50\n",
      "478424/478424 [==============================] - 58s 121us/sample - loss: 0.8709 - acc: 0.8004 - val_loss: 0.7640 - val_acc: 0.8520\n",
      "Epoch 6/50\n",
      "478424/478424 [==============================] - 58s 121us/sample - loss: 0.7887 - acc: 0.8132 - val_loss: 0.7283 - val_acc: 0.8583\n",
      "Epoch 7/50\n",
      "478424/478424 [==============================] - 57s 119us/sample - loss: 0.7238 - acc: 0.8244 - val_loss: 0.7055 - val_acc: 0.8636\n",
      "Epoch 8/50\n",
      "478424/478424 [==============================] - 57s 119us/sample - loss: 0.6723 - acc: 0.8332 - val_loss: 0.6760 - val_acc: 0.8685\n",
      "Epoch 9/50\n",
      "478424/478424 [==============================] - 57s 119us/sample - loss: 0.6306 - acc: 0.8407 - val_loss: 0.6724 - val_acc: 0.8709\n",
      "Epoch 10/50\n",
      "478424/478424 [==============================] - 57s 119us/sample - loss: 0.5952 - acc: 0.8479 - val_loss: 0.6617 - val_acc: 0.8733\n",
      "Epoch 11/50\n",
      "478424/478424 [==============================] - 57s 119us/sample - loss: 0.5665 - acc: 0.8531 - val_loss: 0.6472 - val_acc: 0.8776\n",
      "Epoch 12/50\n",
      "478424/478424 [==============================] - 57s 119us/sample - loss: 0.5445 - acc: 0.8584 - val_loss: 0.6493 - val_acc: 0.8779\n",
      "Epoch 13/50\n",
      "478424/478424 [==============================] - 57s 119us/sample - loss: 0.5238 - acc: 0.8623 - val_loss: 0.6399 - val_acc: 0.8806\n",
      "Epoch 14/50\n",
      "478424/478424 [==============================] - 57s 119us/sample - loss: 0.5046 - acc: 0.8664 - val_loss: 0.6205 - val_acc: 0.8810\n",
      "Epoch 15/50\n",
      "478424/478424 [==============================] - 57s 119us/sample - loss: 0.4902 - acc: 0.8693 - val_loss: 0.6482 - val_acc: 0.8813\n",
      "Epoch 16/50\n",
      "478424/478424 [==============================] - 57s 120us/sample - loss: 0.4784 - acc: 0.8718 - val_loss: 0.6449 - val_acc: 0.8814\n",
      "Epoch 17/50\n",
      "478424/478424 [==============================] - 57s 119us/sample - loss: 0.3979 - acc: 0.8912 - val_loss: 0.6228 - val_acc: 0.8895\n",
      "Epoch 18/50\n",
      "478424/478424 [==============================] - 57s 119us/sample - loss: 0.3806 - acc: 0.8960 - val_loss: 0.6195 - val_acc: 0.8908\n",
      "Epoch 19/50\n",
      "478424/478424 [==============================] - 57s 119us/sample - loss: 0.3697 - acc: 0.8984 - val_loss: 0.6231 - val_acc: 0.8917\n",
      "Epoch 20/50\n",
      "478424/478424 [==============================] - 57s 119us/sample - loss: 0.3642 - acc: 0.8991 - val_loss: 0.6159 - val_acc: 0.8918\n",
      "Epoch 21/50\n",
      "478424/478424 [==============================] - 57s 119us/sample - loss: 0.3583 - acc: 0.9014 - val_loss: 0.6207 - val_acc: 0.8917\n",
      "Epoch 22/50\n",
      "478424/478424 [==============================] - 57s 119us/sample - loss: 0.3528 - acc: 0.9023 - val_loss: 0.6216 - val_acc: 0.8922\n",
      "Epoch 23/50\n",
      "478424/478424 [==============================] - 57s 119us/sample - loss: 0.3474 - acc: 0.9033 - val_loss: 0.6215 - val_acc: 0.8926\n",
      "Epoch 24/50\n",
      "478424/478424 [==============================] - 57s 119us/sample - loss: 0.3444 - acc: 0.9049 - val_loss: 0.6226 - val_acc: 0.8925\n",
      "Epoch 25/50\n",
      "478424/478424 [==============================] - 57s 119us/sample - loss: 0.3439 - acc: 0.9042 - val_loss: 0.6221 - val_acc: 0.8928\n",
      "102520/102520 [==============================] - ETA: 0s - loss: 0.6161 - acc: 0.891 - 12s 116us/sample - loss: 0.6159 - acc: 0.8918\n",
      "Test convolution up\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0909 09:23:01.544853  3672 callbacks.py:875] `period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 478424 samples, validate on 102520 samples\n",
      "Epoch 1/50\n",
      "478424/478424 [==============================] - 147s 307us/sample - loss: 2.0865 - acc: 0.6313 - val_loss: 0.9861 - val_acc: 0.8188\n",
      "Epoch 2/50\n",
      "478424/478424 [==============================] - 142s 297us/sample - loss: 1.0061 - acc: 0.7944 - val_loss: 0.7001 - val_acc: 0.8649\n",
      "Epoch 3/50\n",
      "478424/478424 [==============================] - 142s 297us/sample - loss: 0.7502 - acc: 0.8339 - val_loss: 0.5999 - val_acc: 0.8832\n",
      "Epoch 4/50\n",
      "478424/478424 [==============================] - 142s 297us/sample - loss: 0.6137 - acc: 0.8550 - val_loss: 0.5423 - val_acc: 0.8946\n",
      "Epoch 5/50\n",
      "478424/478424 [==============================] - 142s 297us/sample - loss: 0.5234 - acc: 0.8702 - val_loss: 0.5136 - val_acc: 0.8995\n",
      "Epoch 6/50\n",
      "478424/478424 [==============================] - 142s 297us/sample - loss: 0.4573 - acc: 0.8828 - val_loss: 0.4964 - val_acc: 0.9050\n",
      "Epoch 7/50\n",
      "478424/478424 [==============================] - 142s 297us/sample - loss: 0.4064 - acc: 0.8921 - val_loss: 0.4911 - val_acc: 0.9076\n",
      "Epoch 8/50\n",
      "478424/478424 [==============================] - 142s 297us/sample - loss: 0.3666 - acc: 0.9010 - val_loss: 0.4805 - val_acc: 0.9095\n",
      "Epoch 9/50\n",
      "478424/478424 [==============================] - 142s 296us/sample - loss: 0.3364 - acc: 0.9073 - val_loss: 0.4920 - val_acc: 0.9093\n",
      "Epoch 10/50\n",
      "478424/478424 [==============================] - 142s 298us/sample - loss: 0.3147 - acc: 0.9122 - val_loss: 0.4986 - val_acc: 0.9106\n",
      "Epoch 11/50\n",
      "478424/478424 [==============================] - 142s 296us/sample - loss: 0.2241 - acc: 0.9354 - val_loss: 0.4874 - val_acc: 0.9175\n",
      "Epoch 12/50\n",
      "478424/478424 [==============================] - 142s 297us/sample - loss: 0.2008 - acc: 0.9417 - val_loss: 0.4879 - val_acc: 0.9190\n",
      "Epoch 13/50\n",
      "478424/478424 [==============================] - 142s 298us/sample - loss: 0.1875 - acc: 0.9452 - val_loss: 0.4870 - val_acc: 0.9196\n",
      "102520/102520 [==============================] - 17s 164us/sample - loss: 0.4805 - acc: 0.9095\n",
      "New param set [5, 7, 6, 9]\n",
      "Test dense down\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0909 09:54:19.076654  3672 callbacks.py:875] `period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 478424 samples, validate on 102520 samples\n",
      "Epoch 1/50\n",
      "478424/478424 [==============================] - 139s 291us/sample - loss: 2.2803 - acc: 0.5909 - val_loss: 1.1071 - val_acc: 0.7929\n",
      "Epoch 2/50\n",
      "478424/478424 [==============================] - 135s 282us/sample - loss: 1.1983 - acc: 0.7547 - val_loss: 0.7920 - val_acc: 0.8473\n",
      "Epoch 3/50\n",
      "478424/478424 [==============================] - 135s 282us/sample - loss: 0.9355 - acc: 0.7948 - val_loss: 0.6629 - val_acc: 0.87049354 - acc:\n",
      "Epoch 4/50\n",
      "478424/478424 [==============================] - 135s 281us/sample - loss: 0.7932 - acc: 0.8179 - val_loss: 0.6047 - val_acc: 0.8814\n",
      "Epoch 5/50\n",
      "478424/478424 [==============================] - 134s 280us/sample - loss: 0.6981 - acc: 0.8346 - val_loss: 0.5602 - val_acc: 0.8897\n",
      "Epoch 6/50\n",
      "478424/478424 [==============================] - 134s 280us/sample - loss: 0.6256 - acc: 0.8468 - val_loss: 0.5274 - val_acc: 0.8947\n",
      "Epoch 7/50\n",
      "478424/478424 [==============================] - 134s 281us/sample - loss: 0.5737 - acc: 0.8570 - val_loss: 0.5100 - val_acc: 0.8988\n",
      "Epoch 8/50\n",
      "478424/478424 [==============================] - 134s 280us/sample - loss: 0.5297 - acc: 0.8644 - val_loss: 0.4912 - val_acc: 0.9032\n",
      "Epoch 9/50\n",
      "478424/478424 [==============================] - 134s 280us/sample - loss: 0.4964 - acc: 0.8710 - val_loss: 0.4939 - val_acc: 0.9035\n",
      "Epoch 10/50\n",
      "478424/478424 [==============================] - 135s 282us/sample - loss: 0.4655 - acc: 0.8774 - val_loss: 0.4913 - val_acc: 0.9064\n",
      "Epoch 11/50\n",
      "478424/478424 [==============================] - 134s 281us/sample - loss: 0.3644 - acc: 0.9012 - val_loss: 0.4665 - val_acc: 0.9142\n",
      "Epoch 12/50\n",
      "478424/478424 [==============================] - 134s 281us/sample - loss: 0.3409 - acc: 0.9070 - val_loss: 0.4635 - val_acc: 0.9155\n",
      "Epoch 13/50\n",
      "478424/478424 [==============================] - 134s 280us/sample - loss: 0.3254 - acc: 0.9111 - val_loss: 0.4657 - val_acc: 0.9163\n",
      "Epoch 14/50\n",
      "478424/478424 [==============================] - 134s 281us/sample - loss: 0.3145 - acc: 0.9135 - val_loss: 0.4608 - val_acc: 0.9175\n",
      "Epoch 15/50\n",
      "478424/478424 [==============================] - 134s 281us/sample - loss: 0.3067 - acc: 0.9148 - val_loss: 0.4600 - val_acc: 0.9178\n",
      "Epoch 16/50\n",
      "478424/478424 [==============================] - 134s 281us/sample - loss: 0.2978 - acc: 0.9177 - val_loss: 0.4605 - val_acc: 0.9183\n",
      "Epoch 17/50\n",
      "478424/478424 [==============================] - 134s 281us/sample - loss: 0.2916 - acc: 0.9188 - val_loss: 0.4606 - val_acc: 0.9195\n",
      "Epoch 18/50\n",
      "478424/478424 [==============================] - 134s 281us/sample - loss: 0.2819 - acc: 0.9214 - val_loss: 0.4615 - val_acc: 0.9194\n",
      "Epoch 19/50\n",
      "478424/478424 [==============================] - 134s 281us/sample - loss: 0.2807 - acc: 0.9218 - val_loss: 0.4620 - val_acc: 0.9197\n",
      "Epoch 20/50\n",
      "478424/478424 [==============================] - 134s 281us/sample - loss: 0.2795 - acc: 0.9220 - val_loss: 0.4615 - val_acc: 0.9197\n",
      "102520/102520 [==============================] - 16s 154us/sample - loss: 0.4600 - acc: 0.9178\n",
      "New param set [5, 7, 6, 8]\n",
      "Test dense up\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0909 10:39:34.835088  3672 callbacks.py:875] `period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 478424 samples, validate on 102520 samples\n",
      "Epoch 1/50\n",
      "478424/478424 [==============================] - 147s 308us/sample - loss: 2.1695 - acc: 0.6151 - val_loss: 1.0282 - val_acc: 0.8104\n",
      "Epoch 2/50\n",
      "478424/478424 [==============================] - 143s 300us/sample - loss: 1.0589 - acc: 0.7847 - val_loss: 0.7189 - val_acc: 0.8620\n",
      "Epoch 3/50\n",
      "478424/478424 [==============================] - 144s 300us/sample - loss: 0.7944 - acc: 0.8246 - val_loss: 0.6035 - val_acc: 0.8826\n",
      "Epoch 4/50\n",
      "478424/478424 [==============================] - 143s 300us/sample - loss: 0.6537 - acc: 0.8475 - val_loss: 0.5464 - val_acc: 0.8934\n",
      "Epoch 5/50\n",
      "478424/478424 [==============================] - 143s 299us/sample - loss: 0.5558 - acc: 0.8644 - val_loss: 0.5231 - val_acc: 0.8985\n",
      "Epoch 6/50\n",
      "478424/478424 [==============================] - 143s 300us/sample - loss: 0.4879 - acc: 0.8760 - val_loss: 0.4972 - val_acc: 0.9028\n",
      "Epoch 7/50\n",
      "478424/478424 [==============================] - 143s 300us/sample - loss: 0.4364 - acc: 0.8863 - val_loss: 0.4803 - val_acc: 0.9076\n",
      "Epoch 8/50\n",
      "478424/478424 [==============================] - 143s 299us/sample - loss: 0.3917 - acc: 0.8952 - val_loss: 0.4776 - val_acc: 0.9104\n",
      "Epoch 9/50\n",
      "478424/478424 [==============================] - 144s 301us/sample - loss: 0.3604 - acc: 0.9020 - val_loss: 0.4820 - val_acc: 0.9115\n",
      "Epoch 10/50\n",
      "478424/478424 [==============================] - 144s 301us/sample - loss: 0.3326 - acc: 0.9085 - val_loss: 0.4801 - val_acc: 0.9127\n",
      "Epoch 11/50\n",
      "478424/478424 [==============================] - 143s 300us/sample - loss: 0.2428 - acc: 0.9307 - val_loss: 0.4731 - val_acc: 0.9193\n",
      "Epoch 12/50\n",
      "478424/478424 [==============================] - 143s 299us/sample - loss: 0.2190 - acc: 0.9369 - val_loss: 0.4735 - val_acc: 0.9209\n",
      "Epoch 13/50\n",
      "478424/478424 [==============================] - 143s 299us/sample - loss: 0.2061 - acc: 0.9403 - val_loss: 0.4753 - val_acc: 0.9212\n",
      "Epoch 14/50\n",
      "478424/478424 [==============================] - 143s 299us/sample - loss: 0.1938 - acc: 0.9436 - val_loss: 0.4737 - val_acc: 0.9216\n",
      "Epoch 15/50\n",
      "478424/478424 [==============================] - 143s 299us/sample - loss: 0.1912 - acc: 0.9443 - val_loss: 0.4752 - val_acc: 0.9219\n",
      "Epoch 16/50\n",
      "478424/478424 [==============================] - 143s 299us/sample - loss: 0.1907 - acc: 0.9444 - val_loss: 0.4747 - val_acc: 0.9220\n",
      "102520/102520 [==============================] - 16s 161us/sample - loss: 0.4731 - acc: 0.9193\n",
      "Test dropout down\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0909 11:18:19.240695  3672 callbacks.py:875] `period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 478424 samples, validate on 102520 samples\n",
      "Epoch 1/50\n",
      "478424/478424 [==============================] - 140s 292us/sample - loss: 2.1545 - acc: 0.6130 - val_loss: 1.0348 - val_acc: 0.8052\n",
      "Epoch 2/50\n",
      "478424/478424 [==============================] - 135s 283us/sample - loss: 1.0497 - acc: 0.7827 - val_loss: 0.7245 - val_acc: 0.8581\n",
      "Epoch 3/50\n",
      "478424/478424 [==============================] - 135s 283us/sample - loss: 0.7906 - acc: 0.8224 - val_loss: 0.6092 - val_acc: 0.8796\n",
      "Epoch 4/50\n",
      "478424/478424 [==============================] - 135s 283us/sample - loss: 0.6536 - acc: 0.8457 - val_loss: 0.5482 - val_acc: 0.8917\n",
      "Epoch 5/50\n",
      "478424/478424 [==============================] - 135s 283us/sample - loss: 0.5635 - acc: 0.8611 - val_loss: 0.5274 - val_acc: 0.8964\n",
      "Epoch 6/50\n",
      "478424/478424 [==============================] - 135s 283us/sample - loss: 0.4981 - acc: 0.8731 - val_loss: 0.5017 - val_acc: 0.9026\n",
      "Epoch 7/50\n",
      "478424/478424 [==============================] - 135s 283us/sample - loss: 0.4481 - acc: 0.8827 - val_loss: 0.4892 - val_acc: 0.9056\n",
      "Epoch 8/50\n",
      "478424/478424 [==============================] - 135s 283us/sample - loss: 0.4106 - acc: 0.8903 - val_loss: 0.4829 - val_acc: 0.9075\n",
      "Epoch 9/50\n",
      "478424/478424 [==============================] - 135s 283us/sample - loss: 0.3812 - acc: 0.8968 - val_loss: 0.4895 - val_acc: 0.9093\n",
      "Epoch 10/50\n",
      "478424/478424 [==============================] - 136s 284us/sample - loss: 0.3576 - acc: 0.9019 - val_loss: 0.4846 - val_acc: 0.9120\n",
      "Epoch 11/50\n",
      "478424/478424 [==============================] - 135s 282us/sample - loss: 0.2631 - acc: 0.9253 - val_loss: 0.4734 - val_acc: 0.9181\n",
      "Epoch 12/50\n",
      "478424/478424 [==============================] - 135s 282us/sample - loss: 0.2402 - acc: 0.9313 - val_loss: 0.4728 - val_acc: 0.9197\n",
      "Epoch 13/50\n",
      "478424/478424 [==============================] - 135s 282us/sample - loss: 0.2284 - acc: 0.9344 - val_loss: 0.4714 - val_acc: 0.9205\n",
      "Epoch 14/50\n",
      "478424/478424 [==============================] - 135s 282us/sample - loss: 0.2187 - acc: 0.9370 - val_loss: 0.4695 - val_acc: 0.9210\n",
      "Epoch 15/50\n",
      "478424/478424 [==============================] - 135s 282us/sample - loss: 0.2123 - acc: 0.9384 - val_loss: 0.4721 - val_acc: 0.9213\n",
      "Epoch 16/50\n",
      "478424/478424 [==============================] - 135s 281us/sample - loss: 0.2068 - acc: 0.9399 - val_loss: 0.4746 - val_acc: 0.9216\n",
      "Epoch 17/50\n",
      "478424/478424 [==============================] - 135s 282us/sample - loss: 0.1970 - acc: 0.9422 - val_loss: 0.4731 - val_acc: 0.9222\n",
      "Epoch 18/50\n",
      "478424/478424 [==============================] - 135s 282us/sample - loss: 0.1952 - acc: 0.9429 - val_loss: 0.4734 - val_acc: 0.9224\n",
      "Epoch 19/50\n",
      "478424/478424 [==============================] - 135s 282us/sample - loss: 0.1935 - acc: 0.9430 - val_loss: 0.4733 - val_acc: 0.9224\n",
      "102520/102520 [==============================] - 16s 160us/sample - loss: 0.4695 - acc: 0.9210\n",
      "Test dropout up\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0909 12:01:36.221519  3672 callbacks.py:875] `period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 478424 samples, validate on 102520 samples\n",
      "Epoch 1/50\n",
      "478424/478424 [==============================] - 140s 293us/sample - loss: 2.4748 - acc: 0.5557 - val_loss: 1.2477 - val_acc: 0.7689\n",
      "Epoch 2/50\n",
      "478424/478424 [==============================] - 136s 284us/sample - loss: 1.4074 - acc: 0.7162 - val_loss: 0.8952 - val_acc: 0.8290\n",
      "Epoch 3/50\n",
      "478424/478424 [==============================] - 136s 285us/sample - loss: 1.1307 - acc: 0.7592 - val_loss: 0.7559 - val_acc: 0.8526\n",
      "Epoch 4/50\n",
      "478424/478424 [==============================] - 136s 284us/sample - loss: 0.9768 - acc: 0.7841 - val_loss: 0.6875 - val_acc: 0.8656\n",
      "Epoch 5/50\n",
      "478424/478424 [==============================] - 136s 284us/sample - loss: 0.8749 - acc: 0.8005 - val_loss: 0.6250 - val_acc: 0.8779\n",
      "Epoch 6/50\n",
      "478424/478424 [==============================] - 136s 284us/sample - loss: 0.7941 - acc: 0.8140 - val_loss: 0.5914 - val_acc: 0.8832\n",
      "Epoch 7/50\n",
      "478424/478424 [==============================] - 136s 284us/sample - loss: 0.7354 - acc: 0.8247 - val_loss: 0.5619 - val_acc: 0.8885\n",
      "Epoch 8/50\n",
      "478424/478424 [==============================] - 136s 284us/sample - loss: 0.6885 - acc: 0.8328 - val_loss: 0.5463 - val_acc: 0.8914\n",
      "Epoch 9/50\n",
      "478424/478424 [==============================] - 136s 284us/sample - loss: 0.6509 - acc: 0.8400 - val_loss: 0.5296 - val_acc: 0.8962\n",
      "Epoch 10/50\n",
      "478424/478424 [==============================] - 136s 284us/sample - loss: 0.6184 - acc: 0.8458 - val_loss: 0.5131 - val_acc: 0.8993618\n",
      "Epoch 11/50\n",
      "478424/478424 [==============================] - 136s 284us/sample - loss: 0.5901 - acc: 0.8512 - val_loss: 0.5188 - val_acc: 0.8983\n",
      "Epoch 12/50\n",
      "478424/478424 [==============================] - 136s 284us/sample - loss: 0.5706 - acc: 0.8545 - val_loss: 0.4967 - val_acc: 0.9019\n",
      "Epoch 13/50\n",
      "478424/478424 [==============================] - 136s 284us/sample - loss: 0.5512 - acc: 0.8584 - val_loss: 0.5025 - val_acc: 0.9022\n",
      "Epoch 14/50\n",
      "478424/478424 [==============================] - 136s 284us/sample - loss: 0.5355 - acc: 0.8620 - val_loss: 0.4950 - val_acc: 0.9035\n",
      "Epoch 15/50\n",
      "478424/478424 [==============================] - 136s 284us/sample - loss: 0.5234 - acc: 0.8638 - val_loss: 0.4883 - val_acc: 0.9047\n",
      "Epoch 16/50\n",
      "478424/478424 [==============================] - 136s 284us/sample - loss: 0.5134 - acc: 0.8664 - val_loss: 0.4908 - val_acc: 0.9057\n",
      "Epoch 17/50\n",
      "478424/478424 [==============================] - 136s 284us/sample - loss: 0.5036 - acc: 0.8687 - val_loss: 0.4848 - val_acc: 0.9050\n",
      "Epoch 18/50\n",
      "478424/478424 [==============================] - 136s 284us/sample - loss: 0.4946 - acc: 0.8703 - val_loss: 0.4903 - val_acc: 0.9066\n",
      "Epoch 19/50\n",
      "478424/478424 [==============================] - 137s 285us/sample - loss: 0.4840 - acc: 0.8731 - val_loss: 0.4849 - val_acc: 0.9076\n",
      "Epoch 20/50\n",
      "478424/478424 [==============================] - 135s 282us/sample - loss: 0.3957 - acc: 0.8932 - val_loss: 0.4731 - val_acc: 0.9133\n",
      "Epoch 21/50\n",
      "478424/478424 [==============================] - 135s 282us/sample - loss: 0.3720 - acc: 0.8986 - val_loss: 0.4688 - val_acc: 0.9147\n",
      "Epoch 22/50\n",
      "478424/478424 [==============================] - 135s 282us/sample - loss: 0.3600 - acc: 0.9014 - val_loss: 0.4729 - val_acc: 0.9148\n",
      "Epoch 23/50\n",
      "478424/478424 [==============================] - 135s 282us/sample - loss: 0.3508 - acc: 0.9041 - val_loss: 0.4667 - val_acc: 0.9156\n",
      "Epoch 24/50\n",
      "478424/478424 [==============================] - 136s 284us/sample - loss: 0.3443 - acc: 0.9054 - val_loss: 0.4658 - val_acc: 0.9161\n",
      "Epoch 25/50\n",
      "478424/478424 [==============================] - 135s 282us/sample - loss: 0.3381 - acc: 0.9074 - val_loss: 0.4646 - val_acc: 0.9167\n",
      "Epoch 26/50\n",
      "478424/478424 [==============================] - 135s 282us/sample - loss: 0.3313 - acc: 0.9080 - val_loss: 0.4632 - val_acc: 0.9173\n",
      "Epoch 27/50\n",
      "478424/478424 [==============================] - 135s 282us/sample - loss: 0.3261 - acc: 0.9097 - val_loss: 0.4650 - val_acc: 0.9174\n",
      "Epoch 28/50\n",
      "478424/478424 [==============================] - 135s 282us/sample - loss: 0.3215 - acc: 0.9103 - val_loss: 0.4613 - val_acc: 0.9177\n",
      "Epoch 29/50\n",
      "478424/478424 [==============================] - 135s 282us/sample - loss: 0.3181 - acc: 0.9115 - val_loss: 0.4612 - val_acc: 0.9177\n",
      "Epoch 30/50\n",
      "478424/478424 [==============================] - 135s 282us/sample - loss: 0.3133 - acc: 0.9127 - val_loss: 0.4669 - val_acc: 0.9170\n",
      "Epoch 31/50\n",
      "478424/478424 [==============================] - 135s 282us/sample - loss: 0.3071 - acc: 0.9145 - val_loss: 0.4641 - val_acc: 0.9178\n",
      "Epoch 32/50\n",
      "478424/478424 [==============================] - 135s 282us/sample - loss: 0.3054 - acc: 0.9145 - val_loss: 0.4633 - val_acc: 0.9179\n",
      "Epoch 33/50\n",
      "478424/478424 [==============================] - 135s 282us/sample - loss: 0.3029 - acc: 0.9151 - val_loss: 0.4635 - val_acc: 0.9179\n",
      "Epoch 34/50\n",
      "478424/478424 [==============================] - 135s 283us/sample - loss: 0.3047 - acc: 0.9147 - val_loss: 0.4636 - val_acc: 0.9180\n",
      "102520/102520 [==============================] - 17s 163us/sample - loss: 0.4612 - acc: 0.9177\n",
      "Test batchsize down\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0909 13:18:55.029570  3672 callbacks.py:875] `period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 478424 samples, validate on 102520 samples\n",
      "Epoch 1/50\n",
      "478424/478424 [==============================] - 167s 348us/sample - loss: 2.3348 - acc: 0.5869 - val_loss: 1.2442 - val_acc: 0.7764\n",
      "Epoch 2/50\n",
      "478424/478424 [==============================] - 161s 336us/sample - loss: 1.3885 - acc: 0.7271 - val_loss: 0.9681 - val_acc: 0.8222s - loss: 1.3\n",
      "Epoch 3/50\n",
      "478424/478424 [==============================] - 161s 336us/sample - loss: 1.1439 - acc: 0.7637 - val_loss: 0.8254 - val_acc: 0.8453\n",
      "Epoch 4/50\n",
      "478424/478424 [==============================] - 161s 336us/sample - loss: 1.0048 - acc: 0.7849 - val_loss: 0.7572 - val_acc: 0.8557\n",
      "Epoch 5/50\n",
      "478424/478424 [==============================] - 161s 336us/sample - loss: 0.9035 - acc: 0.8016 - val_loss: 0.6984 - val_acc: 0.8664A: 4s - loss:  - ETA: 0s - loss: 0.9032 - - ETA: 0s - loss: 0.9035 - acc: 0.8\n",
      "Epoch 6/50\n",
      "478424/478424 [==============================] - 161s 336us/sample - loss: 0.8302 - acc: 0.8133 - val_loss: 0.6638 - val_acc: 0.8728\n",
      "Epoch 7/50\n",
      "478424/478424 [==============================] - 161s 336us/sample - loss: 0.7788 - acc: 0.8205 - val_loss: 0.6380 - val_acc: 0.8798\n",
      "Epoch 8/50\n",
      "478424/478424 [==============================] - 161s 336us/sample - loss: 0.7386 - acc: 0.8274 - val_loss: 0.6197 - val_acc: 0.8811\n",
      "Epoch 9/50\n",
      "478424/478424 [==============================] - 161s 336us/sample - loss: 0.7088 - acc: 0.8321 - val_loss: 0.6040 - val_acc: 0.8844\n",
      "Epoch 10/50\n",
      "478424/478424 [==============================] - 161s 337us/sample - loss: 0.6840 - acc: 0.8366 - val_loss: 0.5966 - val_acc: 0.8859\n",
      "Epoch 11/50\n",
      "478424/478424 [==============================] - 161s 336us/sample - loss: 0.6587 - acc: 0.8414 - val_loss: 0.5840 - val_acc: 0.8881\n",
      "Epoch 12/50\n",
      "478424/478424 [==============================] - 164s 342us/sample - loss: 0.6424 - acc: 0.8441 - val_loss: 0.5764 - val_acc: 0.8902loss: 0.6422 - acc: 0.8\n",
      "Epoch 13/50\n",
      "478424/478424 [==============================] - 162s 339us/sample - loss: 0.6247 - acc: 0.8474 - val_loss: 0.5764 - val_acc: 0.8906\n",
      "Epoch 14/50\n",
      "478424/478424 [==============================] - 162s 339us/sample - loss: 0.6097 - acc: 0.8502 - val_loss: 0.5722 - val_acc: 0.8904\n",
      "Epoch 15/50\n",
      "478424/478424 [==============================] - 162s 339us/sample - loss: 0.5948 - acc: 0.8531 - val_loss: 0.5831 - val_acc: 0.8895\n",
      "Epoch 16/50\n",
      "478424/478424 [==============================] - 162s 339us/sample - loss: 0.5845 - acc: 0.8554 - val_loss: 0.5892 - val_acc: 0.8883\n",
      "Epoch 17/50\n",
      "478424/478424 [==============================] - 161s 337us/sample - loss: 0.4593 - acc: 0.8819 - val_loss: 0.5389 - val_acc: 0.9007\n",
      "Epoch 18/50\n",
      "478424/478424 [==============================] - 161s 337us/sample - loss: 0.4293 - acc: 0.8882 - val_loss: 0.5277 - val_acc: 0.9030\n",
      "Epoch 19/50\n",
      "478424/478424 [==============================] - 161s 337us/sample - loss: 0.4129 - acc: 0.8918 - val_loss: 0.5211 - val_acc: 0.9046\n",
      "Epoch 20/50\n",
      "478424/478424 [==============================] - 161s 337us/sample - loss: 0.4035 - acc: 0.8946 - val_loss: 0.5212 - val_acc: 0.9054\n",
      "Epoch 21/50\n",
      "478424/478424 [==============================] - 161s 337us/sample - loss: 0.3931 - acc: 0.8965 - val_loss: 0.5299 - val_acc: 0.9046ETA: 0s - loss: 0.3932 - acc: 0.896 - ETA: 0s - loss: 0.3932 - acc: 0\n",
      "Epoch 22/50\n",
      "478424/478424 [==============================] - 161s 337us/sample - loss: 0.3801 - acc: 0.8994 - val_loss: 0.5203 - val_acc: 0.90583 - ETA:\n",
      "Epoch 23/50\n",
      "478424/478424 [==============================] - 161s 337us/sample - loss: 0.3773 - acc: 0.9002 - val_loss: 0.5192 - val_acc: 0.9060 - loss: 0.3776 -  - ETA: 3s - loss: 0.3776 - acc: 0.9 - ETA: 3s - loss - E - ETA: 0s - loss: 0.3773 - acc: 0\n",
      "Epoch 24/50\n",
      "478424/478424 [==============================] - 161s 337us/sample - loss: 0.3760 - acc: 0.9006 - val_loss: 0.5174 - val_acc: 0.9061\n",
      "Epoch 25/50\n",
      "478424/478424 [==============================] - 161s 337us/sample - loss: 0.3750 - acc: 0.9005 - val_loss: 0.5188 - val_acc: 0.9061\n",
      "Epoch 26/50\n",
      "478424/478424 [==============================] - 161s 337us/sample - loss: 0.3726 - acc: 0.9013 - val_loss: 0.5181 - val_acc: 0.9064s - loss\n",
      "Epoch 27/50\n",
      "478424/478424 [==============================] - 161s 337us/sample - loss: 0.3714 - acc: 0.9016 - val_loss: 0.5180 - val_acc: 0.9064\n",
      "Epoch 28/50\n",
      "478424/478424 [==============================] - 161s 337us/sample - loss: 0.3719 - acc: 0.9016 - val_loss: 0.5180 - val_acc: 0.9063\n",
      "Epoch 29/50\n",
      "478424/478424 [==============================] - 161s 337us/sample - loss: 0.3734 - acc: 0.9004 - val_loss: 0.5180 - val_acc: 0.9063\n",
      "102520/102520 [==============================] - 17s 168us/sample - loss: 0.5174 - acc: 0.9061\n",
      "Test batchsize up\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0909 14:37:27.038489  3672 callbacks.py:875] `period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 478424 samples, validate on 102520 samples\n",
      "Epoch 1/50\n",
      "478424/478424 [==============================] - 126s 263us/sample - loss: 2.4248 - acc: 0.5651 - val_loss: 1.1310 - val_acc: 0.7861\n",
      "Epoch 2/50\n",
      "478424/478424 [==============================] - 121s 252us/sample - loss: 1.1966 - acc: 0.7519 - val_loss: 0.7605 - val_acc: 0.8478\n",
      "Epoch 3/50\n",
      "478424/478424 [==============================] - 120s 252us/sample - loss: 0.8998 - acc: 0.7992 - val_loss: 0.6206 - val_acc: 0.8727\n",
      "Epoch 4/50\n",
      "478424/478424 [==============================] - 120s 252us/sample - loss: 0.7481 - acc: 0.8239 - val_loss: 0.5562 - val_acc: 0.8863\n",
      "Epoch 5/50\n",
      "478424/478424 [==============================] - 120s 252us/sample - loss: 0.6506 - acc: 0.8414 - val_loss: 0.5219 - val_acc: 0.8932\n",
      "Epoch 6/50\n",
      "478424/478424 [==============================] - 120s 252us/sample - loss: 0.5849 - acc: 0.8529 - val_loss: 0.4940 - val_acc: 0.8997\n",
      "Epoch 7/50\n",
      "478424/478424 [==============================] - 120s 252us/sample - loss: 0.5319 - acc: 0.8641 - val_loss: 0.4805 - val_acc: 0.9038\n",
      "Epoch 8/50\n",
      "478424/478424 [==============================] - 120s 252us/sample - loss: 0.4891 - acc: 0.8726 - val_loss: 0.4714 - val_acc: 0.9068\n",
      "Epoch 9/50\n",
      "478424/478424 [==============================] - 120s 252us/sample - loss: 0.4578 - acc: 0.8786 - val_loss: 0.4655 - val_acc: 0.9101\n",
      "Epoch 10/50\n",
      "478424/478424 [==============================] - 120s 252us/sample - loss: 0.4308 - acc: 0.8848 - val_loss: 0.4595 - val_acc: 0.9105\n",
      "Epoch 11/50\n",
      "478424/478424 [==============================] - 120s 252us/sample - loss: 0.4088 - acc: 0.8893 - val_loss: 0.4534 - val_acc: 0.9116\n",
      "Epoch 12/50\n",
      "478424/478424 [==============================] - 120s 252us/sample - loss: 0.3890 - acc: 0.8941 - val_loss: 0.4547 - val_acc: 0.9141\n",
      "Epoch 13/50\n",
      "478424/478424 [==============================] - 120s 251us/sample - loss: 0.3711 - acc: 0.8984 - val_loss: 0.4462 - val_acc: 0.9152\n",
      "Epoch 14/50\n",
      "478424/478424 [==============================] - 120s 252us/sample - loss: 0.3565 - acc: 0.9013 - val_loss: 0.4565 - val_acc: 0.9155\n",
      "Epoch 15/50\n",
      "478424/478424 [==============================] - 121s 253us/sample - loss: 0.3419 - acc: 0.9049 - val_loss: 0.4497 - val_acc: 0.9164\n",
      "Epoch 16/50\n",
      "478424/478424 [==============================] - 121s 252us/sample - loss: 0.2721 - acc: 0.9224 - val_loss: 0.4407 - val_acc: 0.9224\n",
      "Epoch 17/50\n",
      "478424/478424 [==============================] - 120s 252us/sample - loss: 0.2519 - acc: 0.9274 - val_loss: 0.4404 - val_acc: 0.9232\n",
      "Epoch 18/50\n",
      "478424/478424 [==============================] - 120s 252us/sample - loss: 0.2429 - acc: 0.9301 - val_loss: 0.4411 - val_acc: 0.9238\n",
      "Epoch 19/50\n",
      "478424/478424 [==============================] - 120s 251us/sample - loss: 0.2371 - acc: 0.9314 - val_loss: 0.4419 - val_acc: 0.9244\n",
      "Epoch 20/50\n",
      "478424/478424 [==============================] - 120s 252us/sample - loss: 0.2258 - acc: 0.9341 - val_loss: 0.4436 - val_acc: 0.9248\n",
      "Epoch 21/50\n",
      "478424/478424 [==============================] - 120s 251us/sample - loss: 0.2256 - acc: 0.9344 - val_loss: 0.4431 - val_acc: 0.9250\n",
      "Epoch 22/50\n",
      "478424/478424 [==============================] - 120s 252us/sample - loss: 0.2238 - acc: 0.9349 - val_loss: 0.4432 - val_acc: 0.9250\n",
      "102520/102520 [==============================] - 17s 170us/sample - loss: 0.4404 - acc: 0.9232\n",
      "New param set [5, 8, 6, 8]\n",
      "Test convolution down\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0909 15:22:10.459061  3672 callbacks.py:875] `period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 478424 samples, validate on 102520 samples\n",
      "Epoch 1/50\n",
      "478424/478424 [==============================] - 69s 145us/sample - loss: 2.6489 - acc: 0.5247 - val_loss: 1.3306 - val_acc: 0.7443\n",
      "Epoch 2/50\n",
      "478424/478424 [==============================] - 64s 134us/sample - loss: 1.3917 - acc: 0.7146 - val_loss: 0.9171 - val_acc: 0.8181\n",
      "Epoch 3/50\n",
      "478424/478424 [==============================] - 64s 134us/sample - loss: 1.0677 - acc: 0.7653 - val_loss: 0.7555 - val_acc: 0.8466\n",
      "Epoch 4/50\n",
      "478424/478424 [==============================] - 64s 134us/sample - loss: 0.9008 - acc: 0.7921 - val_loss: 0.6798 - val_acc: 0.8619\n",
      "Epoch 5/50\n",
      "478424/478424 [==============================] - 64s 134us/sample - loss: 0.7963 - acc: 0.8100 - val_loss: 0.6258 - val_acc: 0.8730\n",
      "Epoch 6/50\n",
      "478424/478424 [==============================] - 64s 134us/sample - loss: 0.7230 - acc: 0.8236 - val_loss: 0.5938 - val_acc: 0.8798\n",
      "Epoch 7/50\n",
      "478424/478424 [==============================] - 64s 134us/sample - loss: 0.6641 - acc: 0.8349 - val_loss: 0.5732 - val_acc: 0.8855\n",
      "Epoch 8/50\n",
      "478424/478424 [==============================] - 64s 134us/sample - loss: 0.6214 - acc: 0.8427 - val_loss: 0.5541 - val_acc: 0.8896\n",
      "Epoch 9/50\n",
      "478424/478424 [==============================] - 64s 134us/sample - loss: 0.5845 - acc: 0.8501 - val_loss: 0.5420 - val_acc: 0.8929\n",
      "Epoch 10/50\n",
      "478424/478424 [==============================] - 64s 134us/sample - loss: 0.5513 - acc: 0.8571 - val_loss: 0.5389 - val_acc: 0.8942\n",
      "Epoch 11/50\n",
      "478424/478424 [==============================] - 64s 134us/sample - loss: 0.5285 - acc: 0.8622 - val_loss: 0.5258 - val_acc: 0.8961\n",
      "Epoch 12/50\n",
      "478424/478424 [==============================] - 64s 134us/sample - loss: 0.5076 - acc: 0.8665 - val_loss: 0.5319 - val_acc: 0.8966\n",
      "Epoch 13/50\n",
      "478424/478424 [==============================] - 64s 134us/sample - loss: 0.4885 - acc: 0.8708 - val_loss: 0.5130 - val_acc: 0.9018\n",
      "Epoch 14/50\n",
      "478424/478424 [==============================] - 64s 134us/sample - loss: 0.4726 - acc: 0.8745 - val_loss: 0.5114 - val_acc: 0.90220s - loss: 0.4726 - acc: 0 - ETA: 0s - loss: 0.4727 - acc: 0.874\n",
      "Epoch 15/50\n",
      "478424/478424 [==============================] - 64s 134us/sample - loss: 0.4592 - acc: 0.8767 - val_loss: 0.5149 - val_acc: 0.9025\n",
      "Epoch 16/50\n",
      "478424/478424 [==============================] - 65s 136us/sample - loss: 0.4441 - acc: 0.8804 - val_loss: 0.5133 - val_acc: 0.9045\n",
      "Epoch 17/50\n",
      "478424/478424 [==============================] - 64s 134us/sample - loss: 0.3758 - acc: 0.8964 - val_loss: 0.5011 - val_acc: 0.9097\n",
      "Epoch 18/50\n",
      "478424/478424 [==============================] - 64s 134us/sample - loss: 0.3567 - acc: 0.9014 - val_loss: 0.4973 - val_acc: 0.9105\n",
      "Epoch 19/50\n",
      "478424/478424 [==============================] - 64s 134us/sample - loss: 0.3481 - acc: 0.9042 - val_loss: 0.4992 - val_acc: 0.9111\n",
      "Epoch 20/50\n",
      "478424/478424 [==============================] - 64s 134us/sample - loss: 0.3427 - acc: 0.9049 - val_loss: 0.4933 - val_acc: 0.9122ss: 0.343 - ETA: 2s - loss: 0.3428  - ETA: 1s - lo\n",
      "Epoch 21/50\n",
      "478424/478424 [==============================] - 64s 134us/sample - loss: 0.3369 - acc: 0.9068 - val_loss: 0.4940 - val_acc: 0.9126: 0.906\n",
      "Epoch 22/50\n",
      "478424/478424 [==============================] - 64s 134us/sample - loss: 0.3346 - acc: 0.9067 - val_loss: 0.4952 - val_acc: 0.9123\n",
      "Epoch 23/50\n",
      "478424/478424 [==============================] - 64s 134us/sample - loss: 0.3256 - acc: 0.9090 - val_loss: 0.4958 - val_acc: 0.9123\n",
      "Epoch 24/50\n",
      "478424/478424 [==============================] - 64s 134us/sample - loss: 0.3223 - acc: 0.9104 - val_loss: 0.4957 - val_acc: 0.9124\n",
      "Epoch 25/50\n",
      "478424/478424 [==============================] - 64s 134us/sample - loss: 0.3218 - acc: 0.9102 - val_loss: 0.4956 - val_acc: 0.9124\n",
      "102520/102520 [==============================] - 15s 150us/sample - loss: 0.4933 - acc: 0.9122\n",
      "Test convolution up\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0909 15:49:26.984940  3672 callbacks.py:875] `period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 478424 samples, validate on 102520 samples\n",
      "Epoch 1/50\n",
      "478424/478424 [==============================] - 249s 521us/sample - loss: 2.5057 - acc: 0.5530 - val_loss: 1.0765 - val_acc: 0.7954\n",
      "Epoch 2/50\n",
      "478424/478424 [==============================] - 242s 506us/sample - loss: 1.1276 - acc: 0.7668 - val_loss: 0.7004 - val_acc: 0.8587\n",
      "Epoch 3/50\n",
      "478424/478424 [==============================] - 244s 510us/sample - loss: 0.8246 - acc: 0.8152 - val_loss: 0.5660 - val_acc: 0.8841\n",
      "Epoch 4/50\n",
      "478424/478424 [==============================] - 242s 506us/sample - loss: 0.6720 - acc: 0.8415 - val_loss: 0.4985 - val_acc: 0.8970\n",
      "Epoch 5/50\n",
      "478424/478424 [==============================] - 242s 505us/sample - loss: 0.5762 - acc: 0.8578 - val_loss: 0.4683 - val_acc: 0.9047\n",
      "Epoch 6/50\n",
      "478424/478424 [==============================] - 242s 506us/sample - loss: 0.5115 - acc: 0.8704 - val_loss: 0.4535 - val_acc: 0.9089\n",
      "Epoch 7/50\n",
      "478424/478424 [==============================] - 244s 509us/sample - loss: 0.4620 - acc: 0.8795 - val_loss: 0.4473 - val_acc: 0.9119\n",
      "Epoch 8/50\n",
      "478424/478424 [==============================] - 242s 505us/sample - loss: 0.4213 - acc: 0.8881 - val_loss: 0.4365 - val_acc: 0.9155\n",
      "Epoch 9/50\n",
      "478424/478424 [==============================] - 242s 505us/sample - loss: 0.3938 - acc: 0.8941 - val_loss: 0.4347 - val_acc: 0.9177\n",
      "Epoch 10/50\n",
      "478424/478424 [==============================] - 242s 505us/sample - loss: 0.3667 - acc: 0.8999 - val_loss: 0.4325 - val_acc: 0.9188\n",
      "Epoch 11/50\n",
      "478424/478424 [==============================] - 243s 509us/sample - loss: 0.3462 - acc: 0.9046 - val_loss: 0.4326 - val_acc: 0.9195\n",
      "Epoch 12/50\n",
      "478424/478424 [==============================] - 242s 506us/sample - loss: 0.3285 - acc: 0.9083 - val_loss: 0.4250 - val_acc: 0.9220\n",
      "Epoch 13/50\n",
      "478424/478424 [==============================] - 241s 504us/sample - loss: 0.3132 - acc: 0.9121 - val_loss: 0.4430 - val_acc: 0.9201\n",
      "Epoch 14/50\n",
      "478424/478424 [==============================] - 242s 506us/sample - loss: 0.2999 - acc: 0.9150 - val_loss: 0.4244 - val_acc: 0.9224\n",
      "Epoch 15/50\n",
      "478424/478424 [==============================] - 243s 509us/sample - loss: 0.2858 - acc: 0.9184 - val_loss: 0.4376 - val_acc: 0.9220\n",
      "Epoch 16/50\n",
      "478424/478424 [==============================] - 242s 507us/sample - loss: 0.2726 - acc: 0.9212 - val_loss: 0.4431 - val_acc: 0.9230\n",
      "Epoch 17/50\n",
      "478424/478424 [==============================] - 241s 503us/sample - loss: 0.2095 - acc: 0.9380 - val_loss: 0.4405 - val_acc: 0.9279\n",
      "Epoch 18/50\n",
      "478424/478424 [==============================] - 241s 504us/sample - loss: 0.1904 - acc: 0.9434 - val_loss: 0.4404 - val_acc: 0.9288\n",
      "Epoch 19/50\n",
      "478424/478424 [==============================] - 243s 508us/sample - loss: 0.1809 - acc: 0.9457 - val_loss: 0.4415 - val_acc: 0.9290\n",
      "102520/102520 [==============================] - 27s 268us/sample - loss: 0.4244 - acc: 0.9224\n",
      "New param set [5, 8, 7, 8]\n",
      "Test dense down\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0909 17:06:55.364366  3672 callbacks.py:875] `period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 478424 samples, validate on 102520 samples\n",
      "Epoch 1/50\n",
      "478424/478424 [==============================] - 278s 581us/sample - loss: 2.7663 - acc: 0.4993 - val_loss: 1.3661 - val_acc: 0.7431\n",
      "Epoch 2/50\n",
      "478424/478424 [==============================] - 272s 568us/sample - loss: 1.5263 - acc: 0.6892 - val_loss: 0.9256 - val_acc: 0.8193\n",
      "Epoch 3/50\n",
      "478424/478424 [==============================] - 271s 566us/sample - loss: 1.2124 - acc: 0.7392 - val_loss: 0.7557 - val_acc: 0.8480\n",
      "Epoch 4/50\n",
      "478424/478424 [==============================] - 276s 576us/sample - loss: 1.0436 - acc: 0.7673 - val_loss: 0.6632 - val_acc: 0.8657\n",
      "Epoch 5/50\n",
      "478424/478424 [==============================] - 271s 567us/sample - loss: 0.9272 - acc: 0.7872 - val_loss: 0.6058 - val_acc: 0.8769\n",
      "Epoch 6/50\n",
      "478424/478424 [==============================] - 271s 567us/sample - loss: 0.8444 - acc: 0.8024 - val_loss: 0.5670 - val_acc: 0.8852\n",
      "Epoch 7/50\n",
      "478424/478424 [==============================] - 270s 565us/sample - loss: 0.7762 - acc: 0.8147 - val_loss: 0.5447 - val_acc: 0.8898\n",
      "Epoch 8/50\n",
      "478424/478424 [==============================] - 276s 576us/sample - loss: 0.7179 - acc: 0.8253 - val_loss: 0.5214 - val_acc: 0.8959\n",
      "Epoch 9/50\n",
      "478424/478424 [==============================] - 271s 567us/sample - loss: 0.6717 - acc: 0.8347 - val_loss: 0.5029 - val_acc: 0.9000\n",
      "Epoch 10/50\n",
      "478424/478424 [==============================] - 271s 567us/sample - loss: 0.6341 - acc: 0.8421 - val_loss: 0.4967 - val_acc: 0.9029\n",
      "Epoch 11/50\n",
      "478424/478424 [==============================] - 271s 565us/sample - loss: 0.6001 - acc: 0.8481 - val_loss: 0.4855 - val_acc: 0.9048\n",
      "Epoch 12/50\n",
      "478424/478424 [==============================] - 275s 576us/sample - loss: 0.5704 - acc: 0.8544 - val_loss: 0.4743 - val_acc: 0.9068\n",
      "Epoch 13/50\n",
      "478424/478424 [==============================] - 271s 566us/sample - loss: 0.5484 - acc: 0.8585 - val_loss: 0.4700 - val_acc: 0.9095\n",
      "Epoch 14/50\n",
      "478424/478424 [==============================] - 271s 566us/sample - loss: 0.5250 - acc: 0.8638 - val_loss: 0.4662 - val_acc: 0.9110\n",
      "Epoch 15/50\n",
      "478424/478424 [==============================] - 270s 565us/sample - loss: 0.5077 - acc: 0.8669 - val_loss: 0.4706 - val_acc: 0.9109\n",
      "Epoch 16/50\n",
      "478424/478424 [==============================] - 275s 575us/sample - loss: 0.4903 - acc: 0.8709 - val_loss: 0.4566 - val_acc: 0.9127\n",
      "Epoch 17/50\n",
      "478424/478424 [==============================] - 271s 566us/sample - loss: 0.4773 - acc: 0.8739 - val_loss: 0.4583 - val_acc: 0.9140\n",
      "Epoch 18/50\n",
      "478424/478424 [==============================] - 272s 569us/sample - loss: 0.4610 - acc: 0.8770 - val_loss: 0.4621 - val_acc: 0.9143\n",
      "Epoch 19/50\n",
      "478424/478424 [==============================] - 271s 566us/sample - loss: 0.3844 - acc: 0.8953 - val_loss: 0.4438 - val_acc: 0.9203\n",
      "Epoch 20/50\n",
      "478424/478424 [==============================] - 275s 575us/sample - loss: 0.3619 - acc: 0.9006 - val_loss: 0.4447 - val_acc: 0.9206\n",
      "Epoch 21/50\n",
      "478424/478424 [==============================] - 271s 566us/sample - loss: 0.3519 - acc: 0.9042 - val_loss: 0.4401 - val_acc: 0.9224\n",
      "Epoch 22/50\n",
      "478424/478424 [==============================] - 271s 566us/sample - loss: 0.3423 - acc: 0.9056 - val_loss: 0.4404 - val_acc: 0.9224\n",
      "Epoch 23/50\n",
      "478424/478424 [==============================] - 270s 565us/sample - loss: 0.3340 - acc: 0.9072 - val_loss: 0.4394 - val_acc: 0.9228\n",
      "Epoch 24/50\n",
      "478424/478424 [==============================] - 275s 575us/sample - loss: 0.3285 - acc: 0.9088 - val_loss: 0.4395 - val_acc: 0.9231\n",
      "Epoch 25/50\n",
      "478424/478424 [==============================] - 271s 566us/sample - loss: 0.3249 - acc: 0.9099 - val_loss: 0.4374 - val_acc: 0.9235\n",
      "Epoch 26/50\n",
      "478424/478424 [==============================] - 271s 566us/sample - loss: 0.3171 - acc: 0.9122 - val_loss: 0.4398 - val_acc: 0.9235\n",
      "Epoch 27/50\n",
      "478424/478424 [==============================] - 270s 565us/sample - loss: 0.3130 - acc: 0.9126 - val_loss: 0.4407 - val_acc: 0.9239\n",
      "Epoch 28/50\n",
      "478424/478424 [==============================] - 275s 575us/sample - loss: 0.3055 - acc: 0.9142 - val_loss: 0.4407 - val_acc: 0.9238\n",
      "Epoch 29/50\n",
      "478424/478424 [==============================] - 271s 566us/sample - loss: 0.3043 - acc: 0.9147 - val_loss: 0.4402 - val_acc: 0.9240\n",
      "Epoch 30/50\n",
      "478424/478424 [==============================] - 271s 566us/sample - loss: 0.3034 - acc: 0.9148 - val_loss: 0.4402 - val_acc: 0.9240\n",
      "102520/102520 [==============================] - 28s 269us/sample - loss: 0.4374 - acc: 0.9235\n",
      "Test dense up\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0909 19:23:39.743093  3672 callbacks.py:875] `period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 478424 samples, validate on 102520 samples\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[25600,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node Adam_46/Adam/update_dense_46/kernel/ResourceApplyAdam}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-ee2100078689>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0moptimizeHyperParameter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcreateModel1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'../models/KMNIST1.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-3-5d0a698cab76>\u001b[0m in \u001b[0;36moptimizeHyperParameter\u001b[1;34m(funcCreateModel, filenameModel, dropoutLimit, batchSizeLimit, convolutionLayerLimit, denseLayerLimit, maxIter)\u001b[0m\n\u001b[0;32m    135\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Test dense up\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m             testLoss = trainAndEvaluateModel(funcCreateModel(curentParam[0]/20., 2**(curentParam[2]), 2**(curentParam[3]+1)),\n\u001b[1;32m--> 137\u001b[1;33m                                              'temp.h5', 2**(curentParam[1]))\n\u001b[0m\u001b[0;32m    138\u001b[0m             \u001b[0mtestedParam\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcurentParam\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurentParam\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurentParam\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurentParam\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-5d0a698cab76>\u001b[0m in \u001b[0;36mtrainAndEvaluateModel\u001b[1;34m(model, filenameModel, batchSize)\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sparse_categorical_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     model.fit(image[:nVal], charOutput[:nVal], epochs=50, batch_size=batchSize,\n\u001b[1;32m---> 20\u001b[1;33m               validation_data=(image[nVal:nFrac], charOutput[nVal:nFrac]), shuffle=True, callbacks=callbacks)\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilenameModel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    778\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m           \u001b[0mvalidation_freq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m           steps_name='steps_per_epoch')\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m         \u001b[1;31m# Get outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 363\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    364\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\env\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 3292\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\env\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1458\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1459\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[25600,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node Adam_46/Adam/update_dense_46/kernel/ResourceApplyAdam}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n"
     ]
    }
   ],
   "source": [
    "optimizeHyperParameter(createModel1, '../models/KMNIST1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "def sizeof_fmt(num, suffix='B'):\n",
    "    ''' by Fred Cirera,  https://stackoverflow.com/a/1094933/1870254, modified'''\n",
    "    for unit in ['','Ki','Mi','Gi','Ti','Pi','Ei','Zi']:\n",
    "        if abs(num) < 1024.0:\n",
    "            return \"%3.1f %s%s\" % (num, unit, suffix)\n",
    "        num /= 1024.0\n",
    "    return \"%.1f %s%s\" % (num, 'Yi', suffix)\n",
    "\n",
    "for name, size in sorted(((name, sys.getsizeof(value)) for name, value in locals().items()),\n",
    "                         key= lambda x: -x[1])[:10]:\n",
    "    print(\"{:>30}: {:>8}\".format(name, sizeof_fmt(size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(683464, 32, 32, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5339.5625"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.nbytes/1024/1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.float16"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.float16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
